---
redirect_from:
  - "/chapter-13/01-properties-of-covariance"
interact_link: content/Chapter_13/01_Properties_of_Covariance.ipynb
kernel_name: python3
kernel_path: content/Chapter_13
has_widgets: false
title: |-
  Properties of Covariance
pagenum: 65
prev_page:
  url: /Chapter_13/00_Variance_Via_Covariance.html
next_page:
  url: /Chapter_13/02_Sums_of_IID_Samples.html
suffix: .ipynb
search: x y cov covariance e z var xy product muy variance sum independent properties mux expected align property uncorrelated below products mean get example random variables sumx sumy behaves observations sums simple routine algebra constants dont its any c follows useful later terms begin end minus means fact square result simplifies just calculations addition rule shows expand easy ax n j m not units centimeters show independence xyp text lets examine next sections our calculate variances sample establishing involves done expect fill rest recall dxdy vary title duh quality still worth noting constant extension concept because dx dxdx itself symmetric

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Properties of Covariance</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Properties-of-Covariance">Properties of Covariance<a class="anchor-link" href="#Properties-of-Covariance"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's examine how covariance behaves. In the next two sections we will use our observations to calculate variances of sample sums.</p>
<p>Establishing properties of covariance involves simple observations and routine algebra. We have done some of it below, and we expect that you can fill in the rest.</p>
<p>Recall that the covariance of $X$ and $Y$ is</p>
$$
Cov(X, Y) ~ = ~ E(D_XD_Y) ~ = ~ E[(X - \mu_X)(Y - \mu_Y)]
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Constants-Don't-Vary">Constants Don't Vary<a class="anchor-link" href="#Constants-Don't-Vary"> </a></h3><p>That title has a "duh" quality. But it's still worth noting that for any constant $c$,
$$
Cov(X, c) = 0
$$</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Variance-is-a-Covariance">Variance is a Covariance<a class="anchor-link" href="#Variance-is-a-Covariance"> </a></h3><p>Covariance is an extension of the concept of variance, because</p>
$$
Var(X) = E(D_X^2) = E(D_XD_X) = Cov(X, X)
$$<p>The variance of $X$ is the covariance of $X$ and itself.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Covariance-is-Symmetric">Covariance is Symmetric<a class="anchor-link" href="#Covariance-is-Symmetric"> </a></h3><p>Clearly $Cov(Y, X) = Cov(X, Y)$. It follows that</p>
$$
Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y) = Var(X) + Var(Y) + Cov(X, Y) + Cov(Y, X)
$$<p>This way of thinking about the variance of a sum will be useful later.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Covariance-and-Expected-Products">Covariance and Expected Products<a class="anchor-link" href="#Covariance-and-Expected-Products"> </a></h3><p>Covariance <em>is</em> an expected product: it is the expected product of deviations. It can also be written in terms of the expected product of $X$ and $Y$, as follows.</p>
$$
\begin{align*}
Cov(X, Y) &amp;= E[(X - \mu_X)(Y - \mu_Y)] \\
&amp;= E(XY) - E(X)\mu_Y - \mu_XE(Y) + \mu_X\mu_Y \\
&amp;= E(XY) - \mu_X\mu_Y
\end{align*}
$$<p>So covariance is the <em>mean of the product minus the product of the means</em>. Take $X = Y$ to get the familiar fact that variance is the mean of the square minus the square of the mean.</p>
<p>This result simplifies proofs of facts about covariance, as you will see below. But as a computational tool, it is only useful when the distributions of $X$ and $Y$ are very simple â€“ for example, when each has just a few possible values. In other calculations of covariance it is rarely a good idea to try to use this result. Rather, we will use the properties below.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Addition-Rule">Addition Rule<a class="anchor-link" href="#Addition-Rule"> </a></h3><p>A routine application of the property above shows that for any random variables $X$, $Y$, and $Z$,</p>
$$
Cov(X+Y, Z) ~ = ~ Cov(X, Z) + Cov(Y, Z)
$$<p>Just write $Cov(X+Y, Z) = E[(X+Y)Z] - E(X+Y)E(Z)$, expand both products, and collect terms.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Main-Property:-Bilinearity">The Main Property: Bilinearity<a class="anchor-link" href="#The-Main-Property:-Bilinearity"> </a></h3><p>This is the key to using covariance. First, easy algebra shows that for constants $a$ and $b$,
$$
Cov(aX, bY) = abCov(X, Y)
$$</p>
<p>Put this together with the addition rule to get</p>
$$
Cov(aX + bY, cZ) = acCov(X, Z) + bcCov(Y, Z)
$$<p>You can see that covariance behaves like products. By induction,</p>
$$
Cov(\sum_{i=1}^n a_iX_i, \sum_{j=1}^m b_jY_j) ~ = ~
\sum_{i=1}^n\sum_{j=1}^m a_ib_jCov(X_i, Y_j)
$$<p>That might look intimidating, but in fact this property greatly simplifies calculation. It says that you can expand covariance like the product of two sums. For example,</p>
$$
Cov(10X - Y, 3Y + Z) = 30Cov(X, Y) + 10Cov(X, Z) - 3Cov(Y, Y) - Cov(Y, Z)
$$<p>You can replace $Cov(Y, Y)$ by $Var(Y)$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These properties simplify calculations. But they don't give a sense of what covariance means. Indeed it's not easy to understand covariance physically as it has nasty units: for example, if $X$ is a weight in kilograms and $Y$ is height in centimeters, then the units of covariance is <em>kilogram centimeters</em>. Later in the course we will see how to normalize covariance to get the <em>correlation coefficient</em> that you used so often in Data 8. For now, here is a property that begins to show you that covariance can be helpful in quantifying dependence and independence.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Independent-Implies-Uncorrelated">Independent Implies Uncorrelated<a class="anchor-link" href="#Independent-Implies-Uncorrelated"> </a></h3><p>Let $X$ and $Y$ be independent. Then</p>
$$
\begin{align*}
E(XY) &amp;= \sum_x\sum_y xyP(X=x, Y=y) ~~~~~~ \text{(expectation of a function)} \\
&amp;= \sum_x\sum_y xyP(X=x)P(Y=y) ~~~~ \text{(independence)} \\
&amp;= \sum_x xP(X=x) \sum_y yP(Y=y) \\
&amp;= E(X)E(Y)
\end{align*}
$$<p>Therefore if $X$ and $Y$ are independent, then $Cov(X, Y) = 0$. We say that $X$ and $Y$ are <em>uncorrelated</em>.</p>
<p>We have shown that independent random variables are uncorrelated. But it is not true that uncorrelated random variables have to be independent. You will show this in an exercise.</p>

</div>
</div>
</div>
</div>

 


    </main>
    