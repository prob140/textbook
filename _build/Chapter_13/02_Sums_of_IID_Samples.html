---
redirect_from:
  - "/chapter-13/02-sums-of-iid-samples"
interact_link: content/Chapter_13/02_Sums_of_IID_Samples.ipynb
kernel_name: python3
has_widgets: false
title: 'Sums of IID Samples'
prev_page:
  url: /Chapter_13/01_Properties_of_Covariance.html
  title: 'Properties of Covariance'
next_page:
  url: /Chapter_13/03_Sums_of_Simple_Random_Samples.html
  title: 'Sums of Simple Random Samples'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sums-of-IID-Samples">Sums of IID Samples<a class="anchor-link" href="#Sums-of-IID-Samples"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After the dry, algebraic discussion of the previous section it is a relief to finally be able to compute some variances.</p>
<p>Let $X_1, X_2, \ldots X_n$ be random variables with sum
$$
S_n = \sum_{i=1}^n X_i
$$
The variance of the sum is</p>
$$
\begin{align*}
Var(S_n) &amp;= Cov(S_n, S_n) \\
&amp;= \sum_{i=1}^n\sum_{j=1}^n Cov(X_i, X_j) ~~~~ \text{(bilinearity)} \\
&amp;= \sum_{i=1}^n Var(X_i) + \mathop{\sum \sum}_{1 \le i \ne j \le n} Cov(X_i, X_j)
\end{align*}
$$<p>We say that the variance of the sum is the sum of all the variances and all the covariances.</p>
<p>If $X_1, X_2 \ldots , X_n$ are independent, then all the covariance terms in the formula above are 0.</p>
<p>Therefore if $X_1, X_2, \ldots, X_n$ are independent then
$$
Var(S_n) = \sum_{i=1}^n Var(X_i)
$$</p>
<p>Thus for independent random variables $X_1, X_2, \ldots, X_n$, both the expectation and the variance add up nicely:</p>
$$
E(S_n) = \sum_{i=1}^n E(X_i), ~~~~~~ Var(S_n) = \sum_{i=1}^n Var(X_i)
$$<p>When the random variables are i.i.d., this simplifies even further.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sum-of-an-IID-Sample">Sum of an IID Sample<a class="anchor-link" href="#Sum-of-an-IID-Sample"> </a></h3><p>Let $X_1, X_2, \ldots, X_n$ be i.i.d., each with mean $\mu$ and $SD$ $\sigma$. You can think of $X_1, X_2, \ldots, X_n$ as draws at random with replacement from a population, or the results of independent replications of the same experiment.</p>
<p>Let $S_n$ be the sample sum, as above. Then</p>
$$
E(S_n) = n\mu ~~~~~~~~~~ Var(S_n) = n\sigma^2 ~~~~~~~~~~ SD(S_n) = \sqrt{n}\sigma
$$<p>This implies that as the sample size $n$ increases, the distribution of the sum $S_n$ shifts to the right and is more spread out.</p>
<p>Here is one of the most important applications of these results.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Variance-of-the-Binomial">Variance of the Binomial<a class="anchor-link" href="#Variance-of-the-Binomial"> </a></h3><p>Let $X$ have the binomial $(n, p)$ distribution. We know that 
$$
X = \sum_{i=1}^n I_j
$$
where $I_1, I_2, \ldots, I_n$ are i.i.d. indicators, each taking the value 1 with probability $p$. Each of these indicators has expectation $p$ and variance $pq = p(1-p)$. Therefore</p>
$$
E(X) = np ~~~~~~~~~~ Var(X) = npq ~~~~~~~~~~ SD(X) = \sqrt{npq}
$$<p>For example, if $X$ is the number of heads in 100 tosses of a coin, then</p>
$$
E(X) = 100 \times 0.5 = 50 ~~~~~~~~~~ SD(X) = \sqrt{100 \times 0.5 \times 0.5} = 5
$$<p>Here is the distribution of $X$. You can see that there is almost no probability outside the range $E(X) \pm 3SD(X)$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">binom_probs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">binom_dist</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">probabilities</span><span class="p">(</span><span class="n">binom_probs</span><span class="p">)</span>
<span class="n">Plot</span><span class="p">(</span><span class="n">binom_dist</span><span class="p">,</span> <span class="n">show_ev</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_sd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Chapter_13/02_Sums_of_IID_Samples_4_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 

