{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipywidgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatascience\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprob140\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/prob140/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrebinding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Table, Plot, Plots, JointDistribution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkov_chains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkovChain\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msingle_variable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m emp_dist\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/prob140/rebinding.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkov_chains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkovChain, to_markov_chain\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_math\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Plot_continuous\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatascience\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdomain\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/prob140/plots.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interact\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'"
     ]
    }
   ],
   "source": [
    "# HIDDEN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poissonizing the Multinomial ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an extension of Poissonizing the binomial.\n",
    "\n",
    "Suppose you have a sequence of i.i.d. multinomial trials. For example, suppose you are drawing at random with replacement from a population that has $k$ classes of indviduals in proportions $p_1, p_2, \\ldots, p_k$.\n",
    "\n",
    "If you draw a fixed number of times $n$, then the joint distribution of the counts of the classes in the sample is multinomial with parameter $n, p_1, p_2, \\ldots, p_k$. For each fixed $i$, the distribution of the count in Class $i$ is binomial $(n, p_i)$.\n",
    "\n",
    "If you replace the fixed number $n$ of trials by a Poisson $(\\mu)$ random number of trials, then the multinomial gets Poissonized as follows:\n",
    "\n",
    "- For each $i = 1, 2, \\ldots , k$, the distribution of $N_i$ is Poisson $(\\mu p_i)$.\n",
    "- The counts $N_1, N_2, \\ldots , N_k$ in the $k$ different categories are mutually independent.\n",
    "\n",
    "We won't go through the proof which is a straightforward extension of the proof in the case $k=2$ given in an earlier section. Rather, we will look at why the result matters.\n",
    "\n",
    "When the number of trials is fixed, $N_1, N_2, \\ldots , N_k$ are all dependent on each other in complicated ways according to the multinomial distribution. But when you let the sample size be a Poisson random variable, then the independence of the counts $N_1, N_2, \\ldots , N_k$ lets you quickly calculate the chance of any particular configuration of classes in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose that in your population the distribution of classes is as follows:\n",
    "\n",
    "- Class 1: 20%\n",
    "- Class 2: 30%\n",
    "- Class 3: 50%\n",
    "\n",
    "Now suppose you draw $N$ independent times where $N$ has the Poisson $(20)$ distribution. Then in the sample,\n",
    "\n",
    "- the number of Class A individuals has the Poisson distribution with parameter $20$% of $20$, that is Poisson $(4)$,\n",
    "- the number of Class B individuals has the Poisson $(6)$ distribution,\n",
    "- the number of Class C indidviduals has the Poisson $(10)$ distribution,\n",
    "- and these three counts are independent.\n",
    "\n",
    "Note that the Poisson parameters of the three Class counts must add up to the original Poisson parameter of the distribution of $N$. The independence makes it easy to find the chance of any specified configuration of the three classes in the sample: just multiply the three individual Poisson probabilities. \n",
    "\n",
    "For example, the chance that you will get at least 3 individuals in Class A, at least 5 in Class B, and at least 8 in Class C is about 42.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42475602042528027"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - stats.poisson.cdf(2, 4))*(1-stats.poisson.cdf(4, 6))*(1-stats.poisson.cdf(7, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of factors in the answer is equal to the number of classes, unlike the inclusion-exclusion formula in which the amount of work increases much more with each additional class, as you have seen in exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Quick Check\n",
    "Suppose I roll a Poisson $(18)$ number of dice. What is the chance that each face appears at most twice?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Answer\n",
    ":class: dropdown\n",
    "$\\big{(} \\sum_{k=0}^2 e^{-3}\\frac{3^k}{k!} \\big{)}^6$ \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poissonization helps data scientists tackle questions like, \"How many times must I sample so that my chance of seeing at least one individual of each class exceeds a given threshold?\" The answer depends on the distribution of classes in the population, of course, but allowing the sample size be a Poisson random variable can make calculations much more tractable. For applications, see for example the Abstract and References of this [paper](http://people.csail.mit.edu/jayadev/papers/psn_unv_cmp.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}