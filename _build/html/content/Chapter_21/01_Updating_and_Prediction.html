

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>21.1. Updating and Prediction &#8212; Prob 140 Textbook</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/headers.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="21.2. The Beta-Binomial Distribution" href="02_Beta_Binomial_Distribution.html" />
    <link rel="prev" title="21. The Beta and the Binomial" href="00_The_Beta_and_the_Binomial.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Prob 140 Textbook</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="http://prob140.org">
   Course Home
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../To_the_Student.html">
   To the  Student
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_01/00_Fundamentals.html">
   1. Fundamentals
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Outcome_Space_and_Events.html">
     1.1. Outcome Space and Events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Equally_Likely_Outcomes.html">
     1.2. Equally Likely Outcomes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Collisions_in_Hashing.html">
     1.3. Collisions in Hashing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Birthday_Problem.html">
     1.4. The Birthday Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/05_An_Exponential_Approximation.html">
     1.5. An Exponential Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/06_Exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_02/00_Calculating_Chances.html">
   2. Calculating Chances
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_Addition.html">
     2.1. Addition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Examples.html">
     2.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Multiplication.html">
     2.3. Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_More_Examples.html">
     2.4. More Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Updating_Probabilities.html">
     2.5. Updating Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_03/00_Random_Variables.html">
   3. Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Functions_on_an_Outcome_Space.html">
     3.1. Functions on an Outcome Space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Distributions.html">
     3.2. Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_Equality.html">
     3.3. Equality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_Exercises.html">
     3.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_04/00_Relations_Between_Variables.html">
   4. Relations Between Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Joint_Distributions.html">
     4.1. Joint Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Examples.html">
     4.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Marginal_Distributions.html">
     4.3. Marginal Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_Conditional_Distributions.html">
     4.4. Conditional Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Dependence_and_Independence.html">
     4.5. Dependence and Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/06_Exercises.html">
     4.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_05/00_Collections_of_Events.html">
   5. Collections of Events
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Bounding_the_Chance_of_a_Union.html">
     5.1. Bounding the Chance of a Union
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Inclusion_Exclusion.html">
     5.2. Inclusion-Exclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_The_Matching_Problem.html">
     5.3. The Matching Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Sampling_Without_Replacement.html">
     5.4. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Exercises.html">
     5.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_06/00_Random_Counts.html">
   6. Random Counts
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Binomial_Distribution.html">
     6.1. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Examples.html">
     6.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Multinomial_Distribution.html">
     6.3. Multinomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_The_Hypergeometric_Revisited.html">
     6.4. The Hypergeometric, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Odds_Ratios.html">
     6.5. Odds Ratios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/06_Law_of_Small_Numbers.html">
     6.6. The Law of Small Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/07_Exercises.html">
     6.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_07/00_Poissonization.html">
   7. Poissonization
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Poisson_Distribution.html">
     7.1. Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Poissonizing_the_Binomial.html">
     7.2. Poissonizing the Binomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_Poissonizing_the_Multinomial.html">
     7.3. Poissonizing the Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_08/00_Expectation.html">
   8. Expectation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Definition.html">
     8.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Applying_the_Definition.html">
     8.2. Applying the Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Expectations_of_Functions.html">
     8.3. Expectations of Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_Additivity.html">
     8.4. Additivity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Method_of_Indicators.html">
     8.5. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/06_Exercises.html">
     8.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_09/00_Conditioning_Revisited.html">
   9. Conditioning, Revisited
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Probability_by_Conditioning.html">
     9.1. Probability by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Expectation_by_Conditioning.html">
     9.2. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Expected_Waiting_Times.html">
     9.3. Expected Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_Exercises.html">
     9.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_10/00_Markov_Chains.html">
   10. Markov Chains
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Transitions.html">
     10.1. Transitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Deconstructing_Chains.html">
     10.2. Deconstructing Chains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_Long_Run_Behavior.html">
     10.3. Long Run Behavior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_Examples.html">
     10.4. Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_11/00_Markov_Chain_Monte_Carlo.html">
   11. Markov Chain Monte Carlo
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/01_Balance_and_Detailed_Balance.html">
     11.1. Balance and Detailed Balance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/02_Code_Breaking.html">
     11.2. Code Breaking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/03_Metropolis_Algorithm.html">
     11.3. Metropolis Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/04_Exercises.html">
     11.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_12/00_Standard_Deviation.html">
   12. Standard Deviation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/01_Definition.html">
     12.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/02_Prediction_and_Estimation.html">
     12.2. Prediction and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/03_Bounds.html">
     12.3. Tail Bounds
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/04_Heavy_Tails.html">
     12.4. Heavy Tails
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/05_Exercises.html">
     12.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_13/00_Variance_Via_Covariance.html">
   13. Variance Via Covariance
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/01_Covariance.html">
     13.1. Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/02_Properties_of_Covariance.html">
     13.2. Properties of Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/03_Sums_of_Independent_Variables.html">
     13.3. Sums of Independent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/04_Symmetry_and_Indicators.html">
     13.4. Symmetry and Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/05_Finite_Population_Correction.html">
     13.5. Finite Population Correction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/06_Exercises.html">
     13.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_14/00_The_Central_Limit_Theorem.html">
   14. The Central Limit Theorem
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/01_Exact_Distribution_of_a_Sum.html">
     14.1. Exact Distribution of a Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/02_PGFs_in_NumPy.html">
     14.2. PGFs in NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/03_Central_Limit_Theorem.html">
     14.3. Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/04_SciPy_and_Normal_Curves.html">
     14.4. SciPy and Normal Curves
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/05_The_Sample_Mean.html">
     14.5. The Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/06_Confidence_Intervals.html">
     14.6. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/07_Exercises.html">
     14.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_15/00_Continuous_Distributions.html">
   15. Continuous Distributions
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/01_Density_and_CDF.html">
     15.1. Density and CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/02_The_Meaning_of_Density.html">
     15.2. The Meaning of Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/03_Expectation.html">
     15.3. Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/04_Exponential_Distribution.html">
     15.4. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/05_Calculus_in_SymPy.html">
     15.5. Calculus in SymPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/06_Exercises.html">
     15.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_16/00_Transformations.html">
   16. Transformations
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/01_Linear_Transformations.html">
     16.1. Linear Transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/02_Monotone_Functions.html">
     16.2. Monotone Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/03_Simulation_via_the_CDF.html">
     16.3. Simulation via the CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/04_Two_to_One_Functions.html">
     16.4. Two-to-One Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/05_Exercises.html">
     16.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_17/00_Joint_Densities.html">
   17. Joint Densities
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/01_Probabilities_and_Expectations.html">
     17.1. Probabilities and Expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/02_Independence.html">
     17.2. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/03_Marginal_and_Conditional_Densities.html">
     17.3. Marginal and Conditional Densities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/04_Beta_Densities_with_Integer_Parameters.html">
     17.4. Beta Densities with Integer Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/05_Exercises.html">
     17.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_18/00_The_Normal_and_Gamma_Families.html">
   18. The Normal and Gamma Families
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/01_Standard_Normal_Basics.html">
     18.1. Standard Normal: The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/02_Sums_of_Independent_Normal_Variables.html">
     18.2. Sums of Independent Normal Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/03_The_Gamma_Family.html">
     18.3. The Gamma Family
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/04_Chi_Squared_Distributions.html">
     18.4. Chi-Squared Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/05_Exercises.html">
     18.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_19/00_Distributions_of_Sums.html">
   19. Distributions of Sums
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/01_Convolution_Formula.html">
     19.1. The Convolution Formula
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/02_Moment_Generating_Functions.html">
     19.2. Moment Generating Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/03_MGFs_Normal_and_the_CLT.html">
     19.3. MGFs, the Normal, and the CLT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/04_Chernoff_Bound.html">
     19.4. Chernoff Bound
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/05_Exercises.html">
     19.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_20/00_Approaches_to_Estimation.html">
   20. Approaches to Estimation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/01_Maximum_Likelihood.html">
     20.1. Maximum Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/02_Independence_Revisited.html">
     20.2. Independence, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/03_Prior_and_Posterior.html">
     20.3. Prior and Posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/04_Exercises.html">
     20.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="00_The_Beta_and_the_Binomial.html">
   21. The Beta and the Binomial
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     21.1. Updating and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_Beta_Binomial_Distribution.html">
     21.2. The Beta-Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_Long_Run_Proportion_of_Heads.html">
     21.3. Long Run Proportion of Heads
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Exercises.html">
     21.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_22/00_Prediction.html">
   22. Prediction
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/01_Conditional_Expectation_Projection.html">
     22.1. Conditional Expectation As a Projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/02_Variance_by_Conditioning.html">
     22.2. Variance by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/03_Examples.html">
     22.3. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/04_Least_Squares_Predictor.html">
     22.4. Least Squares Predictor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_23/00_Multivariate_Normal_RVs.html">
   23. Jointly Normal Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/01_Random_Vectors.html">
     23.1. Random Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/02_Multivariate_Normal_Distribution.html">
     23.2. Multivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/03_Linear_Combinations.html">
     23.3. Linear Combinations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/04_Independence.html">
     23.4. Independence
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_24/00_Simple_Linear_Regression.html">
   24. Simple Linear Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/01_Bivariate_Normal_Distribution.html">
     24.1. Bivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/02_Linear_Least_Squares.html">
     24.2. Least Squares Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/03_Regression_and_Bivariate_Normal.html">
     24.3. Regression and the Bivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/04_Regression_Equation.html">
     24.4. The Regression Equation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_25/00_Multiple_Regression.html">
   25. Multiple Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/01_Bilinearity_in_Matrix_Notation.html">
     25.1. Bilinearity in Matrix Notation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/02_Best_Linear_Predictor.html">
     25.2. Best Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/03_Multivariate_Normal_Conditioning.html">
     25.3. Conditioning and the Multivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/04_Multiple_Regression.html">
     25.4. Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/05_Further_Review_Exercises.html">
     25.5. Further Review Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Chapter_21/01_Updating_and_Prediction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://prob140.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/textbook&urlpath=tree/textbook/content/Chapter_21/01_Updating_and_Prediction.ipynb&branch=gh-pages"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#beta-prior">
   21.1.1. Beta Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-experiment">
   21.1.2. The Experiment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#updating-the-posterior-distribution-of-x-given-s-n">
   21.1.3. Updating: The Posterior Distribution of
   <span class="math notranslate nohighlight">
    \(X\)
   </span>
   Given
   <span class="math notranslate nohighlight">
    \(S_n\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conjugate-prior">
   21.1.4. Conjugate Prior
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#map-estimate-posterior-mode">
   21.1.5. MAP Estimate: Posterior Mode
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-mean">
   21.1.6. Posterior Mean
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction-the-distribution-of-s-n-1-given-s-n">
   21.1.7. Prediction: The Distribution of
   <span class="math notranslate nohighlight">
    \(S_{n+1}\)
   </span>
   Given
   <span class="math notranslate nohighlight">
    \(S_n\)
   </span>
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="updating-and-prediction">
<h1><span class="section-number">21.1. </span>Updating and Prediction<a class="headerlink" href="#updating-and-prediction" title="Permalink to this headline">¶</a></h1>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random variable with a beta density. Given <span class="math notranslate nohighlight">\(X=p\)</span>, toss a <span class="math notranslate nohighlight">\(p\)</span>-coin <span class="math notranslate nohighlight">\(n\)</span> times and observe the number of heads. Based on the number of heads, we are going to:</p>
<ul class="simple">
<li><p>Identify the posterior distribution of <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>Predict the chance of heads on the <span class="math notranslate nohighlight">\((n+1)\)</span>st toss</p></li>
</ul>
<div class="section" id="beta-prior">
<h2><span class="section-number">21.1.1. </span>Beta Prior<a class="headerlink" href="#beta-prior" title="Permalink to this headline">¶</a></h2>
<p>For positive integers <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span>, we derived the beta <span class="math notranslate nohighlight">\((r, s)\)</span> density</p>
<div class="math notranslate nohighlight">
\[
f(x) = \frac{(r+s-1)!}{(r-1)!(s-1)!} x^{r-1}(1-x)^{s-1}, ~~~ 0 &lt; x &lt; 1
\]</div>
<p>by studying order statistics of i.i.d. uniform <span class="math notranslate nohighlight">\((0, 1)\)</span> random variables. The beta family can be extended to include parameters <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span> that are positive but not integers. This is possible because of two facts that you have observed in exercises:</p>
<ul class="simple">
<li><p>The Gamma function is a continuous extension of the factorial function.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(r\)</span> is a positive integer then <span class="math notranslate nohighlight">\(\Gamma(r) = (r-1)!\)</span>.</p></li>
</ul>
<p>For fixed positive numbers <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span>, not necessarily integers, the beta <span class="math notranslate nohighlight">\((r, s)\)</span> density is defined by</p>
<div class="math notranslate nohighlight">
\[
f(x) = 
\frac{\Gamma(r+s)}{\Gamma(r)\Gamma(s)} x^{r-1}(1-x)^{s-1}, ~~~ 0 &lt; x &lt; 1 
\]</div>
<p>We will not prove that this function integrates to 1, but it is true and should be believable because we have seen it to be true for integer values of the parameters.</p>
<p>To simplify notation, we will denote the constant in the beta <span class="math notranslate nohighlight">\((r, s)\)</span> density by <span class="math notranslate nohighlight">\(C(r, s)\)</span>.</p>
<div class="math notranslate nohighlight">
\[
C(r, s) ~ = ~ \frac{\Gamma(r+s)}{\Gamma(r)\Gamma(s)}
\]</div>
<p>so that the beta <span class="math notranslate nohighlight">\((r, s)\)</span> density is given by <span class="math notranslate nohighlight">\(C(r, s)x^{r-1}(1-x)^{s-1}\)</span> for <span class="math notranslate nohighlight">\(x \in (0, 1)\)</span>.</p>
<p>Beta distributions are often used to model random proportions. In the previous chapter you saw the beta <span class="math notranslate nohighlight">\((1, 1)\)</span> distribution, better known as the uniform, used in this way to model a randomly picked coin.</p>
<p>You also saw that given that we know the value of <span class="math notranslate nohighlight">\(p\)</span> for the coin we are tossing, the tosses are independent, but when we don’t know <span class="math notranslate nohighlight">\(p\)</span> then the tosses are no longer independent. For example, knowledge of how the first toss came out tells us something about <span class="math notranslate nohighlight">\(p\)</span>, which in turn affects the probabilities of how the second toss might come out.</p>
<p>We will now extend these results by starting with a general beta <span class="math notranslate nohighlight">\((r, s)\)</span> prior for the chance that the coin lands heads.</p>
</div>
<div class="section" id="the-experiment">
<h2><span class="section-number">21.1.2. </span>The Experiment<a class="headerlink" href="#the-experiment" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> have the beta <span class="math notranslate nohighlight">\((r, s)\)</span> distribution. This is the prior distribution of <span class="math notranslate nohighlight">\(X\)</span>. Denote the prior density by <span class="math notranslate nohighlight">\(f_X\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[
f_X(p) ~ = ~ C(r, s)p^{r-1}(1-p)^{s-1}, ~~~~ 0 &lt; p &lt; 1
\]</div>
<p>Given <span class="math notranslate nohighlight">\(X = p\)</span>, let <span class="math notranslate nohighlight">\(I_1, I_2, \ldots\)</span> be i.i.d. Bernoulli <span class="math notranslate nohighlight">\((p)\)</span>. That is, given <span class="math notranslate nohighlight">\(X = p\)</span>, toss a <span class="math notranslate nohighlight">\(p\)</span>-coin repeatedly and record the results as <span class="math notranslate nohighlight">\(I_1, I_2, \ldots\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(S_n = I_1 + I_2 + \cdots + I_n\)</span> be the number of heads in the first <span class="math notranslate nohighlight">\(n\)</span> tosses. Then the conditional distribution of <span class="math notranslate nohighlight">\(S_n\)</span> given <span class="math notranslate nohighlight">\(X = p\)</span> is binomial <span class="math notranslate nohighlight">\((n, p)\)</span>. It gives you the likelihood of the observed number of heads given a value of <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="cell tag_remove-input tag_hide-output docutils container">
</div>
</div>
<div class="section" id="updating-the-posterior-distribution-of-x-given-s-n">
<h2><span class="section-number">21.1.3. </span>Updating: The Posterior Distribution of <span class="math notranslate nohighlight">\(X\)</span> Given <span class="math notranslate nohighlight">\(S_n\)</span><a class="headerlink" href="#updating-the-posterior-distribution-of-x-given-s-n" title="Permalink to this headline">¶</a></h2>
<p>Before running the experiment, our prior opinion is that <span class="math notranslate nohighlight">\(X\)</span> has the beta <span class="math notranslate nohighlight">\((r, s)\)</span> distribution. To update that opinion after we have tossed <span class="math notranslate nohighlight">\(n\)</span> times and seen the number of heads, we have to find the posterior distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(S_n = k\)</span>.</p>
<p>As we have seen, the posterior density is proportional to the prior times the likelihood. For <span class="math notranslate nohighlight">\(0 &lt; p &lt; 1\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
f_{X \vert S_n=k} (p) ~ &amp;\propto ~ {C(r, s) p^{r-1}(1-p)^{s-1} \cdot \binom{n}{k} p^k (1-p)^{n-k}}\\ \\
&amp;\propto ~ p^{r+k-1}(1-p)^{s + (n-k) - 1} 
\end{align*}
\end{split}\]</div>
<p>because <span class="math notranslate nohighlight">\(C(r, s)\)</span> and <span class="math notranslate nohighlight">\(\binom{n}{k}\)</span> do not involve <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>You can see at once that this is the beta <span class="math notranslate nohighlight">\((r+k, s+n-k)\)</span> density:</p>
<div class="math notranslate nohighlight">
\[
f_{X \mid S_n = k} (p) ~ = ~ C(r+k, s+n-k) p^{r+k-1}(1-p)^{s + n - k - 1}, ~~~ 0 &lt; p &lt; 1
\]</div>
<p>This beta posterior density is easy to remember. Start with the prior; update the first parameter by adding the observed number of heads; update the second parameter by adding the observed number of tails.</p>
</div>
<div class="section" id="conjugate-prior">
<h2><span class="section-number">21.1.4. </span>Conjugate Prior<a class="headerlink" href="#conjugate-prior" title="Permalink to this headline">¶</a></h2>
<p>The prior distribution of the probability of heads is from the beta family. The posterior distribution of the probability of heads, given the number of heads, is another beta density. The beta prior and binomial likelihood combine to result in a beta posterior. The beta family is therefore called a <em>family of conjugate priors</em> for the binomial distribution: the posterior is another member of the same family as the prior.</p>
</div>
<div class="section" id="map-estimate-posterior-mode">
<h2><span class="section-number">21.1.5. </span>MAP Estimate: Posterior Mode<a class="headerlink" href="#map-estimate-posterior-mode" title="Permalink to this headline">¶</a></h2>
<p>The MAP estimate of the chance of heads is the mode of the posterior distribution. If <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span> are both greater than 1 then the mode of the posterior distribution of <span class="math notranslate nohighlight">\(X\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\frac{r+k-1}{r+s+n-2}
\]</div>
<div class="cell tag_remove-input tag_hide-output docutils container">
</div>
</div>
<div class="section" id="posterior-mean">
<h2><span class="section-number">21.1.6. </span>Posterior Mean<a class="headerlink" href="#posterior-mean" title="Permalink to this headline">¶</a></h2>
<p>The posterior mean of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(S_n = k\)</span> is the expectation of the beta posterior distribution, which for large <span class="math notranslate nohighlight">\(n\)</span> is not far from the mode:</p>
<div class="math notranslate nohighlight">
\[
E(X \mid S_n = k) ~ = ~ \frac{r+k}{r+s+n} 
\]</div>
<p>Let’s examine this result in an example. Suppose the prior distribution of <span class="math notranslate nohighlight">\(X\)</span> is beta <span class="math notranslate nohighlight">\((5, 3)\)</span>, and thus the prior mean is <span class="math notranslate nohighlight">\(E(X) = 5/8 = 0.625\)</span>.  Now suppose we are given that <span class="math notranslate nohighlight">\(S_{100} = 70\)</span>. Then the posterior distribution of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(S_{100} = 70\)</span> is beta <span class="math notranslate nohighlight">\((75, 33)\)</span> with mean <span class="math notranslate nohighlight">\(75/108 = 0.694\)</span>.</p>
<p>The graph below shows the two densities along with the corresponding means. The red dot is at the observed proportion of heads.</p>
<p>Run the cell again, keeping <span class="math notranslate nohighlight">\(r = 5\)</span> and <span class="math notranslate nohighlight">\(s = 3\)</span> but changing <span class="math notranslate nohighlight">\(n\)</span> to 10 and <span class="math notranslate nohighlight">\(k\)</span> to 7, then again changing <span class="math notranslate nohighlight">\(n\)</span> to 1000 and <span class="math notranslate nohighlight">\(k\)</span> to <span class="math notranslate nohighlight">\(700\)</span>. The observed proportion is 0.7 in all cases. Notice how increasing the sample size concentrates the prior around 0.7. We will soon see the reason for this.</p>
<p>Also try other values of the parameters as well as <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(k\)</span>, including values where the observed proportion is quite different from the mean of the prior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prior: beta (r, s)</span>
<span class="c1"># Given: S_n = k</span>

<span class="c1"># Change the values</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">70</span>

<span class="c1"># Leave this line alone</span>
<span class="n">plot_prior_and_posterior</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/01_Updating_and_Prediction_11_0.png" src="../../_images/01_Updating_and_Prediction_11_0.png" />
</div>
</div>
<p>You can see how the data dominate the prior. The posterior distribution is concentrated around the posterior mean. The prior mean was 0.625, but given that we got 70 heads in 100 tosses, the posterior mean is 0.694 which is very close to the observerd proportion 0.7.</p>
<p>The formula for the posterior mean shows that for large <span class="math notranslate nohighlight">\(n\)</span> it is likely to be close to the observed proportion of heads. Given <span class="math notranslate nohighlight">\(S_n = k\)</span>, the posterior mean is</p>
<div class="math notranslate nohighlight">
\[
E(X \mid S_n = k) ~ = ~ \frac{r + k}{r + s + n}
\]</div>
<p>Therefore as a random variable, the posterior mean is</p>
<div class="math notranslate nohighlight">
\[
E(X \mid S_n) ~ = ~ \frac{r + S_n}{r + s + n}
\]</div>
<p>As the number of tosses <span class="math notranslate nohighlight">\(n\)</span> gets large, the number of heads <span class="math notranslate nohighlight">\(S_n\)</span> is likely to get large too. So the value of <span class="math notranslate nohighlight">\(S_n\)</span> is likely to dominate the numerator, and <span class="math notranslate nohighlight">\(n\)</span> will dominate the denominator, because <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span> are constants. Thus for large <span class="math notranslate nohighlight">\(n\)</span>, the posterior mean is likely to be close to <span class="math notranslate nohighlight">\(S_n/n\)</span>.</p>
</div>
<div class="section" id="prediction-the-distribution-of-s-n-1-given-s-n">
<h2><span class="section-number">21.1.7. </span>Prediction: The Distribution of <span class="math notranslate nohighlight">\(S_{n+1}\)</span> Given <span class="math notranslate nohighlight">\(S_n\)</span><a class="headerlink" href="#prediction-the-distribution-of-s-n-1-given-s-n" title="Permalink to this headline">¶</a></h2>
<p>As you saw in the previous chapter, the chance that a random coin lands heads is the expected value of its random probability of heads. Apply this to our current setting to see that</p>
<div class="math notranslate nohighlight">
\[
P(S_1 = 1) ~ = ~ P(\text{first toss is a head}) ~ = ~ E(X) ~ = ~ \frac{r}{r+s}
\]</div>
<p>Now suppose that we have the results of the first <span class="math notranslate nohighlight">\(n\)</span> tosses, and that <span class="math notranslate nohighlight">\(k\)</span> of those tosses were heads. Given that <span class="math notranslate nohighlight">\(S_n = k\)</span>, the possible values of <span class="math notranslate nohighlight">\(S_{n+1}\)</span> are <span class="math notranslate nohighlight">\(k\)</span> and <span class="math notranslate nohighlight">\(k+1\)</span>. We can now use our updated distribution of <span class="math notranslate nohighlight">\(X\)</span> and the same reasoning as above to see that</p>
<div class="math notranslate nohighlight">
\[
P(S_{n+1} = k+1 \mid S_n = k) ~ = ~ P(\text{toss } n+1 \text{ is a head} \mid S_n = k)
~ = ~ E(X \mid S_n = k) ~ = ~ \frac{r+k}{r + s + n}
\]</div>
<p>We can work out <span class="math notranslate nohighlight">\(P(S_{n+1} = k \mid S_n = k)\)</span> by the complement rule. We now have a transition function. Given that <span class="math notranslate nohighlight">\(S_n = k\)</span>, the conditional distribution of <span class="math notranslate nohighlight">\(S_{n+1}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
S_{n+1} =
\begin{cases} 
k ~~~~~~~~ \text{ with probability } (s + n - k)/(r + s + n) \\
k+1 ~~ \text{ with probability } (r+k)/(r + s + n)
\end{cases}
\end{split}\]</div>
<p>In other words, given the results of the first <span class="math notranslate nohighlight">\(n\)</span> tosses, the chance that Toss <span class="math notranslate nohighlight">\(n+1\)</span> is a tail is proportional to <span class="math notranslate nohighlight">\(s\)</span> plus the number of failures. The chance that Toss <span class="math notranslate nohighlight">\(n+1\)</span> is a head is proportional to <span class="math notranslate nohighlight">\(r\)</span> plus the number of successes.</p>
<p>You can think of the sequence <span class="math notranslate nohighlight">\(\{ S_n: n \ge 1 \}\)</span> as a Markov chain, but keep in mind that the transition probabilities are not time-homogenous – the formulas involve <span class="math notranslate nohighlight">\(n\)</span>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/Chapter_21"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="00_The_Beta_and_the_Binomial.html" title="previous page"><span class="section-number">21. </span>The Beta and the Binomial</a>
    <a class='right-next' id="next-link" href="02_Beta_Binomial_Distribution.html" title="next page"><span class="section-number">21.2. </span>The Beta-Binomial Distribution</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>