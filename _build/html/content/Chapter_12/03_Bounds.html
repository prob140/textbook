

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>12.3. Tail Bounds &#8212; Prob 140 Textbook</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/headers.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12.4. Heavy Tails" href="04_Heavy_Tails.html" />
    <link rel="prev" title="12.2. Prediction and Estimation" href="02_Prediction_and_Estimation.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Prob 140 Textbook</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="http://prob140.org">
   Course Home
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../To_the_Student.html">
   To the  Student
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_01/00_Fundamentals.html">
   1. Fundamentals
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Outcome_Space_and_Events.html">
     1.1. Outcome Space and Events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Equally_Likely_Outcomes.html">
     1.2. Equally Likely Outcomes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Collisions_in_Hashing.html">
     1.3. Collisions in Hashing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Birthday_Problem.html">
     1.4. The Birthday Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/05_An_Exponential_Approximation.html">
     1.5. An Exponential Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/06_Exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_02/00_Calculating_Chances.html">
   2. Calculating Chances
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_Addition.html">
     2.1. Addition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Examples.html">
     2.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Multiplication.html">
     2.3. Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_More_Examples.html">
     2.4. More Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Updating_Probabilities.html">
     2.5. Updating Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_03/00_Random_Variables.html">
   3. Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Functions_on_an_Outcome_Space.html">
     3.1. Functions on an Outcome Space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Distributions.html">
     3.2. Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_Equality.html">
     3.3. Equality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_Exercises.html">
     3.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_04/00_Relations_Between_Variables.html">
   4. Relations Between Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Joint_Distributions.html">
     4.1. Joint Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Examples.html">
     4.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Marginal_Distributions.html">
     4.3. Marginal Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_Conditional_Distributions.html">
     4.4. Conditional Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Dependence_and_Independence.html">
     4.5. Dependence and Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/06_Exercises.html">
     4.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_05/00_Collections_of_Events.html">
   5. Collections of Events
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Bounding_the_Chance_of_a_Union.html">
     5.1. Bounding the Chance of a Union
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Inclusion_Exclusion.html">
     5.2. Inclusion-Exclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_The_Matching_Problem.html">
     5.3. The Matching Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Sampling_Without_Replacement.html">
     5.4. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Exercises.html">
     5.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_06/00_Random_Counts.html">
   6. Random Counts
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Binomial_Distribution.html">
     6.1. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Examples.html">
     6.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Multinomial_Distribution.html">
     6.3. Multinomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_The_Hypergeometric_Revisited.html">
     6.4. The Hypergeometric, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Odds_Ratios.html">
     6.5. Odds Ratios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/06_Law_of_Small_Numbers.html">
     6.6. The Law of Small Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/07_Exercises.html">
     6.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_07/00_Poissonization.html">
   7. Poissonization
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Poisson_Distribution.html">
     7.1. Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Poissonizing_the_Binomial.html">
     7.2. Poissonizing the Binomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_Poissonizing_the_Multinomial.html">
     7.3. Poissonizing the Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_08/00_Expectation.html">
   8. Expectation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Definition.html">
     8.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Applying_the_Definition.html">
     8.2. Applying the Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Expectations_of_Functions.html">
     8.3. Expectations of Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_Additivity.html">
     8.4. Additivity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Method_of_Indicators.html">
     8.5. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/06_Exercises.html">
     8.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_09/00_Conditioning_Revisited.html">
   9. Conditioning, Revisited
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Probability_by_Conditioning.html">
     9.1. Probability by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Expectation_by_Conditioning.html">
     9.2. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Expected_Waiting_Times.html">
     9.3. Expected Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_Exercises.html">
     9.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_10/00_Markov_Chains.html">
   10. Markov Chains
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Transitions.html">
     10.1. Transitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Deconstructing_Chains.html">
     10.2. Deconstructing Chains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_Long_Run_Behavior.html">
     10.3. Long Run Behavior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_Examples.html">
     10.4. Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_11/00_Markov_Chain_Monte_Carlo.html">
   11. Markov Chain Monte Carlo
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/01_Balance_and_Detailed_Balance.html">
     11.1. Balance and Detailed Balance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/02_Code_Breaking.html">
     11.2. Code Breaking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/03_Metropolis_Algorithm.html">
     11.3. Metropolis Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/04_Exercises.html">
     11.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="00_Standard_Deviation.html">
   12. Standard Deviation
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_Definition.html">
     12.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_Prediction_and_Estimation.html">
     12.2. Prediction and Estimation
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     12.3. Tail Bounds
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Heavy_Tails.html">
     12.4. Heavy Tails
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_Exercises.html">
     12.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_13/00_Variance_Via_Covariance.html">
   13. Variance Via Covariance
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/01_Covariance.html">
     13.1. Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/02_Properties_of_Covariance.html">
     13.2. Properties of Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/03_Sums_of_Independent_Variables.html">
     13.3. Sums of Independent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/04_Symmetry_and_Indicators.html">
     13.4. Symmetry and Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/05_Finite_Population_Correction.html">
     13.5. Finite Population Correction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/06_Exercises.html">
     13.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_14/00_The_Central_Limit_Theorem.html">
   14. The Central Limit Theorem
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/01_Exact_Distribution.html">
     14.1. Exact Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/02_PGFs_in_NumPy.html">
     14.2. PGFs in NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/03_Central_Limit_Theorem.html">
     14.3. Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/04_The_Sample_Mean.html">
     14.4. The Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/05_Confidence_Intervals.html">
     14.5. Confidence Intervals
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_15/00_Continuous_Distributions.html">
   15. Continuous Distributions
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/01_Density_and_CDF.html">
     15.1. Density and CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/02_The_Meaning_of_Density.html">
     15.2. The Meaning of Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/03_Expectation.html">
     15.3. Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/04_Exponential_Distribution.html">
     15.4. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/05_Calculus_in_SymPy.html">
     15.5. Calculus in SymPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/06_Review_Problems_Set_3.html">
     15.6. Review Problems: Set 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_16/00_Transformations.html">
   16. Transformations
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/01_Linear_Transformations.html">
     16.1. Linear Transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/02_Monotone_Functions.html">
     16.2. Monotone Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/03_Two_to_One_Functions.html">
     16.3. Two-to-One Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_17/00_Joint_Densities.html">
   17. Joint Densities
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/01_Probabilities_and_Expectations.html">
     17.1. Probabilities and Expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/02_Independence.html">
     17.2. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/03_Marginal_and_Conditional_Densities.html">
     17.3. Marginal and Conditional Densities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/04_Beta_Densities_with_Integer_Parameters.html">
     17.4. Beta Densities with Integer Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_18/00_The_Normal_and_Gamma_Families.html">
   18. The Normal and Gamma Families
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/01_Standard_Normal_Basics.html">
     18.1. Standard Normal: The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/02_Sums_of_Independent_Normal_Variables.html">
     18.2. Sums of Independent Normal Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/03_The_Gamma_Family.html">
     18.3. The Gamma Family
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/04_Chi_Squared_Distributions.html">
     18.4. Chi-Squared Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/05_Review_Problems_Set_4.html">
     18.5. Review Problems: Set 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_19/00_Distributions_of_Sums.html">
   19. Distributions of Sums
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/01_Convolution_Formula.html">
     19.1. The Convolution Formula
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/02_Moment_Generating_Functions.html">
     19.2. Moment Generating Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/03_MGFs_Normal_and_the_CLT.html">
     19.3. MGFs, the Normal, and the CLT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/04_Chernoff_Bound.html">
     19.4. Chernoff Bound
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_20/00_Approaches_to_Estimation.html">
   20. Approaches to Estimation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/01_Maximum_Likelihood.html">
     20.1. Maximum Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/02_Prior_and_Posterior.html">
     20.2. Prior and Posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/03_Independence_Revisited.html">
     20.3. Independence, Revisited
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_21/00_The_Beta_and_the_Binomial.html">
   21. The Beta and the Binomial
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/01_Updating_and_Prediction.html">
     21.1. Updating and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/02_Beta_Binomial_Distribution.html">
     21.2. The Beta-Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/03_Long_Run_Proportion_of_Heads.html">
     21.3. Long Run Proportion of Heads
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_22/00_Prediction.html">
   22. Prediction
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/01_Conditional_Expectation_Projection.html">
     22.1. Conditional Expectation As a Projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/02_Variance_by_Conditioning.html">
     22.2. Variance by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/03_Examples.html">
     22.3. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/04_Least_Squares_Predictor.html">
     22.4. Least Squares Predictor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_23/00_Multivariate_Normal_RVs.html">
   23. Jointly Normal Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/01_Random_Vectors.html">
     23.1. Random Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/02_Multivariate_Normal_Distribution.html">
     23.2. Multivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/03_Linear_Combinations.html">
     23.3. Linear Combinations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/04_Independence.html">
     23.4. Independence
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_24/00_Simple_Linear_Regression.html">
   24. Simple Linear Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/01_Bivariate_Normal_Distribution.html">
     24.1. Bivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/02_Linear_Least_Squares.html">
     24.2. Least Squares Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/03_Regression_and_Bivariate_Normal.html">
     24.3. Regression and the Bivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/04_Regression_Equation.html">
     24.4. The Regression Equation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_25/00_Multiple_Regression.html">
   25. Multiple Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/01_Bilinearity_in_Matrix_Notation.html">
     25.1. Bilinearity in Matrix Notation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/02_Best_Linear_Predictor.html">
     25.2. Best Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/03_Multivariate_Normal_Conditioning.html">
     25.3. Conditioning and the Multivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/04_Multiple_Regression.html">
     25.4. Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/05_Further_Review_Exercises.html">
     25.5. Further Review Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Chapter_12/03_Bounds.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://prob140.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/textbook&urlpath=tree/textbook/content/Chapter_12/03_Bounds.ipynb&branch=gh-pages"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monotonicity">
   12.3.1. Monotonicity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-s-inequality">
   12.3.2. Markov’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#another-way-of-writing-markov-s-inequality">
   12.3.3. Another Way of Writing Markov’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chebyshev-s-inequality">
   12.3.4. Chebyshev’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bound-on-one-tail">
   12.3.5. Bound on One Tail
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#another-way-of-writing-chebyshev-s-inequality">
   12.3.6. Another Way of Writing Chebyshev’s Inequality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-units">
   12.3.7. Standard Units
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="tail-bounds">
<h1><span class="section-number">12.3. </span>Tail Bounds<a class="headerlink" href="#tail-bounds" title="Permalink to this headline">¶</a></h1>
<p>If you know <span class="math notranslate nohighlight">\(E(X)\)</span> and <span class="math notranslate nohighlight">\(SD(X)\)</span> you can get some idea of how much probability there is in the tails of the distribution of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>In this section we are going to get upper bounds on probabilities such as the gold area in the graph below. That’s <span class="math notranslate nohighlight">\(P(X \ge 20)\)</span> for the random variable <span class="math notranslate nohighlight">\(X\)</span> whose distribution is displayed in the histogram.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/03_Bounds_3_0.png" src="../../_images/03_Bounds_3_0.png" />
</div>
</div>
<div class="section" id="monotonicity">
<h2><span class="section-number">12.3.1. </span>Monotonicity<a class="headerlink" href="#monotonicity" title="Permalink to this headline">¶</a></h2>
<p>To do this, we will start with an observation about expectations of functions of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Suppose <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(h\)</span> are functions such that <span class="math notranslate nohighlight">\(g(X) \ge h(X)\)</span>, that is, <span class="math notranslate nohighlight">\(P(g(X) \ge h(X)) = 1\)</span>. Then <span class="math notranslate nohighlight">\(E(g(X)) \ge E(h(X))\)</span>.</p>
<p>This result is apparent when you notice that for all <span class="math notranslate nohighlight">\(\omega\)</span> in the outcome space,</p>
<div class="math notranslate nohighlight">
\[
(g \circ X)(\omega) \ge (h \circ X)(\omega) ~~~~ \text{and therefore} ~~~~
(g \circ X)(\omega)P(\omega) \ge (h \circ X)(\omega)P(\omega)
\]</div>
<p>Now suppose <span class="math notranslate nohighlight">\(X\)</span> is a non-negative random variable, and let <span class="math notranslate nohighlight">\(c\)</span> be a positive number. Consider the two functions <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(h\)</span> graphed below.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/03_Bounds_6_0.png" src="../../_images/03_Bounds_6_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># VIDEO: Markov&#39;s Inequality</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;WIokPScne_8&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/WIokPScne_8"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>The function <span class="math notranslate nohighlight">\(h\)</span> is the indicator defined by <span class="math notranslate nohighlight">\(h(x) = I(x \ge c)\)</span>. So <span class="math notranslate nohighlight">\(h(X) = I(X \ge c)\)</span> and <span class="math notranslate nohighlight">\(E(h(X)) = P(X \ge c)\)</span>.</p>
<p>The function <span class="math notranslate nohighlight">\(g\)</span> is constructed so that the graph of <span class="math notranslate nohighlight">\(g\)</span> is a straight line that is at or above the graph of <span class="math notranslate nohighlight">\(h\)</span> on <span class="math notranslate nohighlight">\([0, \infty)\)</span>, with the two graphs meeting at <span class="math notranslate nohighlight">\(x = 0\)</span> and <span class="math notranslate nohighlight">\(x = c\)</span>. The equation of the straight line is <span class="math notranslate nohighlight">\(g(x) = x/c\)</span>.</p>
<p>Thus <span class="math notranslate nohighlight">\(g(X) = X/c\)</span> and hence <span class="math notranslate nohighlight">\(E(g(X)) = E(X/c) = E(X)/c\)</span>.</p>
<p>By construction, <span class="math notranslate nohighlight">\(g(x) \ge h(x)\)</span> for <span class="math notranslate nohighlight">\(x \ge 0\)</span>. Since <span class="math notranslate nohighlight">\(X\)</span> is a non-negative random variable, <span class="math notranslate nohighlight">\(P(g(X) \ge h(X)) = 1\)</span>.</p>
<p>So</p>
<div class="math notranslate nohighlight">
\[
E(X)/c ~ = ~ E(g(X)) ~ \ge ~ E(h(X)) ~ =  ~ P(X \ge c)
\]</div>
<p>We have just proved</p>
</div>
<div class="section" id="markov-s-inequality">
<h2><span class="section-number">12.3.2. </span>Markov’s Inequality<a class="headerlink" href="#markov-s-inequality" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a non-negative random variable. Then for any <span class="math notranslate nohighlight">\(c &gt; 0\)</span>,</p>
<div class="math notranslate nohighlight">
\[
P(X \ge c) ~ \le ~ \frac{E(X)}{c}
\]</div>
<p>This result is called a “tail bound” because it puts an upper limit on how big the right tail at <span class="math notranslate nohighlight">\(c\)</span> can be. It is worth noting that <span class="math notranslate nohighlight">\(P(X &gt; c) \le P(X \ge c) \le E(X)/c\)</span> by Markov’s bound.</p>
<p>In the figure below, <span class="math notranslate nohighlight">\(E(X) = 6.5\)</span> and <span class="math notranslate nohighlight">\(c = 20\)</span>. Markov’s inequality says that the gold area is <em>at most</em></p>
<div class="math notranslate nohighlight">
\[
\frac{6.5}{20} = 0.325
\]</div>
<p>You can see that the bound is pretty crude. The gold area is clearly quite a bit less than 0.325.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/03_Bounds_9_0.png" src="../../_images/03_Bounds_9_0.png" />
</div>
</div>
<div class="admonition-quick-check admonition">
<p class="admonition-title">Quick Check</p>
<p>Students in a dorm have 4 packets of Oreos, on average. Let <span class="math notranslate nohighlight">\(R\)</span> be the number of packets of Oreos that a randomly picked student has. Find or provide lower and upper bounds on <span class="math notranslate nohighlight">\(P(R &gt; 12)\)</span>.</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1/3\)</span></p>
</div>
</div>
<div class="section" id="another-way-of-writing-markov-s-inequality">
<h2><span class="section-number">12.3.3. </span>Another Way of Writing Markov’s Inequality<a class="headerlink" href="#another-way-of-writing-markov-s-inequality" title="Permalink to this headline">¶</a></h2>
<p>Another way to think of Markov’s bound is that if <span class="math notranslate nohighlight">\(X\)</span> is a non-negative random variable with expectation <span class="math notranslate nohighlight">\(\mu_X\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
P(X \ge k\mu_X) ~ \le ~ \frac{1}{k} ~~~ \text{for all } k &gt; 0
\]</div>
<p>That is, <span class="math notranslate nohighlight">\(P(X \ge 2\mu_X) \le 1/2\)</span>, <span class="math notranslate nohighlight">\(P(X \ge 5\mu_X) \le 1/5\)</span>, and so on. The chance that a non-negative random variable is at least <span class="math notranslate nohighlight">\(k\)</span> times the mean is at most <span class="math notranslate nohighlight">\(1/k\)</span>.</p>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k\)</span> need not be an integer. For example, the chance that a non-negative random variable is at least 3.8 times the mean is at most <span class="math notranslate nohighlight">\(1/3.8\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(k \le 1\)</span>, the inequality doesn’t tell you anything you didn’t already know. If <span class="math notranslate nohighlight">\(k \le 1\)</span> then Markov’s bound is 1 or greater. All probabilities are bounded above by 1, so the inequality is true but useless for <span class="math notranslate nohighlight">\(k \le 1\)</span>.</p></li>
<li><p>When <span class="math notranslate nohighlight">\(k\)</span> is large, the bound does tell you something. You are looking at a probability quite far out in the tail of the distribution, and Markov’s bound is <span class="math notranslate nohighlight">\(1/k\)</span> which is small.</p></li>
</ul>
</div>
<div class="section" id="chebyshev-s-inequality">
<h2><span class="section-number">12.3.4. </span>Chebyshev’s Inequality<a class="headerlink" href="#chebyshev-s-inequality" title="Permalink to this headline">¶</a></h2>
<p>Markov’s bound only uses <span class="math notranslate nohighlight">\(E(X)\)</span>, not <span class="math notranslate nohighlight">\(SD(X)\)</span>. To get bounds on tails it seems better to use <span class="math notranslate nohighlight">\(SD(X)\)</span> if we can. <em>Chebyshev’s Inequality</em> does just that. It provides a bound on the two tails outside an interval that is symmetric about <span class="math notranslate nohighlight">\(E(X)\)</span> as in the following graph.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/03_Bounds_14_0.png" src="../../_images/03_Bounds_14_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># VIDEO: Chebyshev&#39;s Inequality</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;n6DilL4PzAQ&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/n6DilL4PzAQ"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>The red arrow marks <span class="math notranslate nohighlight">\(\mu_X\)</span> as usual, and now the two blue arrows are at a distance of <span class="math notranslate nohighlight">\(SD(X)\)</span> on either side of the mean. The gold tails start at the same constant <span class="math notranslate nohighlight">\(c\)</span> on either side of <span class="math notranslate nohighlight">\(\mu\)</span>. We will get an upper bound on the gold area by applying Markov’s Inequality to the non-negative random variable <span class="math notranslate nohighlight">\((X - \mu_X)^2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
P\big{(}|X - \mu_X| \ge c\big{)} &amp;= P\big{(}(X-\mu_X)^2 \ge c^2\big{)} \\ \\
&amp;\le \frac{E\big{[}(X-\mu_X)^2\big{]}}{z^2\sigma_X^2} ~~~~~ \text{(Markov's Inequality)}\\ \\
&amp;= \frac{\sigma_X^2}{c^2} ~~~~~ \text{(definition of variance)} 
\end{align*}
\end{split}\]</div>
<p>The figure below is analogous to the figure drawn earlier to illustrate the derivation of Markov’s inequality.</p>
<p>The graph of the quadratic function <span class="math notranslate nohighlight">\(g(x) = (x - \mu_X)^2/c^2\)</span> is always at or above the graph of the indicator function <span class="math notranslate nohighlight">\(h(x) = I(\vert x - \mu_X \vert \ge c)\)</span>.</p>
<p>Chebyshev’s Inequality is just a restatement of the fact that <span class="math notranslate nohighlight">\(E(g(X)) ~ \ge ~ E(h(X)) ~ = ~ P(\vert X - \mu_X \vert \ge c)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># NO CODE</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mf">5.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">9</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;$\mu_X -c$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\mu_X$&#39;</span><span class="p">,</span> <span class="s1">&#39;$\mu_X +c$&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;$g(x) = (x - \mu_X)^2/c^2$,  $h(x) = I(|x - \mu_X| \geq c)$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/03_Bounds_19_0.png" src="../../_images/03_Bounds_19_0.png" />
</div>
</div>
</div>
<div class="section" id="bound-on-one-tail">
<h2><span class="section-number">12.3.5. </span>Bound on One Tail<a class="headerlink" href="#bound-on-one-tail" title="Permalink to this headline">¶</a></h2>
<p>It is important to remember that Chebyshev’s Inequality just provides an upper bound on the total of two tail probabilities. It is not an exact probability or an approximation. The same upper bound applies for a single tail:</p>
<div class="math notranslate nohighlight">
\[
P(X - \mu_X \ge c) ~ \le ~ P(|X - \mu_X| \le c) ~ \le ~ \frac{\sigma_X^2}{c^2}
\]</div>
<p>Don’t yield to the temptation of dividing the bound by 2. The two tails need not be equal. There is no assumption of symmetry.</p>
<div class="admonition-quick-check admonition">
<p class="admonition-title">Quick Check</p>
<p>Suppose <span class="math notranslate nohighlight">\(E(X) = 50\)</span> and <span class="math notranslate nohighlight">\(SD(X) = 5\)</span>.</p>
<p>(a) Find the best upper bound you can for <span class="math notranslate nohighlight">\(P(\vert X - 50 \vert \ge 30)\)</span>.</p>
<p>(b) Find the best upper bound you can for <span class="math notranslate nohighlight">\(P(X - 50 \ge 30)\)</span>.</p>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<p>Both upper bounds are <span class="math notranslate nohighlight">\(1/36\)</span></p>
</div>
</div>
<div class="section" id="another-way-of-writing-chebyshev-s-inequality">
<h2><span class="section-number">12.3.6. </span>Another Way of Writing Chebyshev’s Inequality<a class="headerlink" href="#another-way-of-writing-chebyshev-s-inequality" title="Permalink to this headline">¶</a></h2>
<p>It is often going to be convenient to think of <span class="math notranslate nohighlight">\(E(X)\)</span> as “the origin” and to measure distances in units of SDs on either side.</p>
<p>Thus we can think of the two tails as the event “<span class="math notranslate nohighlight">\(X\)</span> is at least <span class="math notranslate nohighlight">\(z\)</span> SDs away from <span class="math notranslate nohighlight">\(\mu_X\)</span>”, for some positive <span class="math notranslate nohighlight">\(z\)</span>. Chebyshev’s Inequality says</p>
<div class="math notranslate nohighlight">
\[
P(\vert X - \mu_X \vert \ge z\sigma_X) ~ \le ~ \frac{\sigma_X^2}{z^2\sigma_X^2} ~ = ~ \frac{1}{z^2}
\]</div>
<p>This is the form in which you saw Chebyshev’s Inequality in Data 8.</p>
<p>Chebyshev’s Inequality makes no assumptions about the shape of the distribution. It implies that no matter what the distribution of <span class="math notranslate nohighlight">\(X\)</span> looks like,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\mu_X - 2\sigma_X &lt; X &lt; \mu_X + 2\sigma_X) &gt; 1 - 1/4 = 75\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mu_X - 3\sigma_X &lt; X &lt; \mu_X + 3\sigma_X) &gt; 1 - 1/9 = 88.88...\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mu_X - 4\sigma_X &lt; X &lt; \mu_X + 4\sigma_X) &gt; 1 - 1/16 = 93.75\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mu_X - 5\sigma_X &lt; X &lt; \mu_X + 5\sigma_X) &gt; 1 - 1/25 = 96\%\)</span></p></li>
</ul>
<p>That is, <em>no matter what the shape of the distribution</em>, the bulk of the probability is in the interval “expected value plus or minus a few SDs”.</p>
<p>This is one reason why the SD is a good measure of spread. No matter what the distribution, if you know the expectation and the SD then you have a pretty good sense of where the bulk of the probability is located.</p>
<p>If you happen to know more about the distribution then of course you can do better than Chebyshev’s bound. But in general Chebyshev’s bound is as well as you can do without making further assumptions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># VIDEO: Standard Units</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;y6RF-WBJciY&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/y6RF-WBJciY"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
</div>
<div class="section" id="standard-units">
<h2><span class="section-number">12.3.7. </span>Standard Units<a class="headerlink" href="#standard-units" title="Permalink to this headline">¶</a></h2>
<p>To formalize the notion of “setting <span class="math notranslate nohighlight">\(\mu_X\)</span> as the origin and measuring distances in units of <span class="math notranslate nohighlight">\(\sigma_X\)</span>, we define a random variable <span class="math notranslate nohighlight">\(Z\)</span> called “<span class="math notranslate nohighlight">\(X\)</span> in standard units” as follows:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{X - \mu_X}{\sigma_X}
\]</div>
<p><span class="math notranslate nohighlight">\(Z\)</span> measures how far <span class="math notranslate nohighlight">\(X\)</span> is above its mean, relative to its SD. In other words, <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(Z\)</span> SDs above the mean:</p>
<div class="math notranslate nohighlight">
\[
X = Z\sigma_X + \mu_X
\]</div>
<p>It is important to learn to go back and forth between these two scales of measurement, as we will be using standard units quite frequently. Note that by the linear function rules,</p>
<div class="math notranslate nohighlight">
\[
E(Z) = 0 ~~~~ \text{and} ~~~~ SD(Z) = 1
\]</div>
<p>no matter what the distribution of <span class="math notranslate nohighlight">\(X\)</span> is.</p>
<p>Also note that because <span class="math notranslate nohighlight">\(Var(Z) = 1\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
E(Z^2) ~ = ~ Var(Z) + (E(Z))^2 ~ = ~ 1 + 0^2 ~ = ~ 1
\]</div>
<p>Chebyshev’s Inequality says</p>
<div class="math notranslate nohighlight">
\[
P(|X - \mu_X| \ge z\sigma_X) \le \frac{1}{z^2}
\]</div>
<p>which is the same as saying</p>
<div class="math notranslate nohighlight">
\[
P(|Z| \ge z) \le \frac{1}{z^2}
\]</div>
<p>So if you have converted a random variable to standard units, the overwhelming majority of the values of the standardized variable should be in the range <span class="math notranslate nohighlight">\(-5\)</span> to <span class="math notranslate nohighlight">\(5\)</span>. It is possible that there are values outside that range, but it is not likely.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/Chapter_12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="02_Prediction_and_Estimation.html" title="previous page"><span class="section-number">12.2. </span>Prediction and Estimation</a>
    <a class='right-next' id="next-link" href="04_Heavy_Tails.html" title="next page"><span class="section-number">12.4. </span>Heavy Tails</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>