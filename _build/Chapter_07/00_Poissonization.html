---
redirect_from:
  - "/chapter-07/00-poissonization"
interact_link: content/Chapter_07/00_Poissonization.ipynb
kernel_name: python3
kernel_path: content/Chapter_07
has_widgets: false
title: |-
  Poissonization
pagenum: 36
prev_page:
  url: /Chapter_06/05_Law_of_Small_Numbers.html
next_page:
  url: /Chapter_07/01_Poissonizing_the_Binomial.html
suffix: .ipynb
search: mu distribution x k p poisson e n just probabilities terms additivity finite frac muk infty sum parameter mode function f binomial random variable probability d where le any values spaces infinite our example ldots expansion doesnt axiom theory course here calculate integer c stats large infinitely approximation those proportional series before ai called countable follow not technical aspects axioms prob shape notice left likely value later cumulative area summing distributionname poissonization only between studying behavior gets move outcome motivated developed small under assumptions saw chance successes bernoulli trials roughly approx np stop wont either little care required further must

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Poissonization</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Poissonization">Poissonization<a class="anchor-link" href="#Poissonization"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A binomial $(n, p)$ random variable has a finite number of values: it can only be between 0 and $n$. But now that we are studying the behavior of binomial probabilities as $n$ gets large, it is time to move from finite outcome spaces to spaces that are infinite.</p>
<p>Our first example of a probability distribution on infinitely many values is motivated by the approximation we have developed for the binomial $(n, p)$ distribution when $n$ is large and $p$ is small. Under those assumptions we
saw that the chance of $k$ successes in $n$ i.i.d. Bernoulli $(p)$ trials is roughly</p>
$$
P(k) ~ \approx ~ e^{-\mu} \frac{\mu^k}{k!}, ~~ k = 0, 1, 2, \ldots, n
$$<p>where $\mu = np$.</p>
<p>The terms in the approximation are proportional to terms in the series expansion of $e^\mu$, but <em>that expansion is infinite</em>. It doesn't stop at $n$, so we won't either.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A little care is required before we go further. First, we must state the additivity axiom of probability theory in terms of countably many outcomes:</p>
<p>If events $A_1, A_2, \ldots $ are mutually exclusive, then</p>
$$
P(\bigcup_{i=1}^\infty A_i) ~ = ~ \sum_{i=1}^\infty P(A_i)
$$<p>This is called the <em>countable additivity</em> axiom, in contrast to the finite additivity axiom we have thus far assumed. It doesn't follow from finite additivity, but of course finite additivity follows from it.</p>
<p>In this course, we will not go into the technical aspects of countable additivity and the existence of probability functions that satisfy the axioms on the spaces that interest us. But those technical aspects do have to be studied before you can develop a deeper understanding of probability theory. If you want to do that, a good start is to take Real Analysis and then Measure Theory.</p>
<p>While in Prob 140, you don't have to worry about it. Just assume that all our work is consistent with the axioms.</p>
<p>Here is our first infinite valued distribution.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Poisson-Distribution">Poisson Distribution<a class="anchor-link" href="#Poisson-Distribution"> </a></h3><p>A random variable $X$ has the <em>Poisson distribution with parameter $\mu &gt; 0$</em> if</p>
$$
P(X = k) ~ = ~ e^{-\mu} \frac{\mu^k}{k!}, ~~~~ k = 0, 1, 2, \ldots
$$<p>The terms are proportional to the terms in the infinte series expansion of $e^{\mu}$. These terms $\frac{\mu^k}{k!}$ for $k \ge 0$ determine the shape of the distribution.</p>
<p>The constant of proportionality is $e^{-\mu}$. It doesn't affect the shape. It just ensures that the probabilities add up to 1.</p>
$$
\sum_{k=0}^\infty P(X = k) 
~ = ~ \sum_{k=0}^\infty e^{-\mu} \frac{\mu^k}{k!} 
~ = ~ e^{-\mu} \sum_{k=0}^\infty \frac{\mu^k}{k!} 
~ = ~ e^{-\mu} \cdot e^{\mu} ~ = ~ 1
$$<p></p>
<p>The Poisson is a distribution in its own right. It does not have to arise as a limit, though it is sometimes helpful to think of it that way.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="An-Interpretation-of-the-Parameter">An Interpretation of the Parameter<a class="anchor-link" href="#An-Interpretation-of-the-Parameter"> </a></h3><p>To understand the parameter $\mu$ of the Poisson distribution, a first step is to notice that mode of the distribution is just around $\mu$. Here is an example where $\mu = 3.74$. No computing system can calculate infinitely many probabilities, so we have just calculated the Poisson probabilities till the sum is close enough to 1 that the <code>prob140</code> library considers it a Distribution object.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mf">3.74</span>
<span class="n">k</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">poi_probs_374</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<span class="n">poi_dist_374</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">poi_probs_374</span><span class="p">)</span>
<span class="n">Plot</span><span class="p">(</span><span class="n">poi_dist_374</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Poisson (3.74)&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Chapter_07/00_Poissonization_5_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The mode is 3. To find a formula for the mode, follow the process we used for the binomial: calculate the consecutive odds ratios, notice that they are decreasing, and see where they cross 1. This is left to you as an exercise. Your calculations should conclude the following:</p>
<h4 id="Mode-of-the-Poisson">Mode of the Poisson<a class="anchor-link" href="#Mode-of-the-Poisson"> </a></h4><p>The mode of the Poisson distribution is the integer part of $\mu$. That is, the most likely value is $\mu$ rounded <em>down</em> to an integer. If $\mu$ is an integer, both $\mu$ and $\mu - 1$ are modes.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">k</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">poi_probs_4</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
<span class="n">poi_dist_4</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">probability</span><span class="p">(</span><span class="n">poi_probs_4</span><span class="p">)</span>
<span class="n">Plot</span><span class="p">(</span><span class="n">poi_dist_4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Poisson (4)&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Chapter_07/00_Poissonization_7_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In later chapters we will learn a lot more about the parameter $\mu$ of the Poisson distribution. For now, just keep in mind that the most likely value is essentially $\mu$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Cumulative-Distribution-Function-(c.d.f.)">The Cumulative Distribution Function (c.d.f.)<a class="anchor-link" href="#The-Cumulative-Distribution-Function-(c.d.f.)"> </a></h3><p>Very often, we need probabilities of the form $P(X &gt; x)$ or $P(X \le x)$. For example, if $X$ has the Poisson $(4)$ distribution, here is the event $\{ X \le 5 \}$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Plot</span><span class="p">(</span><span class="n">poi_dist_4</span><span class="p">,</span> <span class="n">event</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Poisson (4)&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/Chapter_07/00_Poissonization_10_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <em>cumulative distribution function</em> or c.d.f. of any random variable is a function that calculates this "area to the left" of any point. If you denote the c.d.f. by $F$, then
$$
F(x) = P(X \le x)
$$
for any x.</p>
<p>We will get to know this function better later in the course. For now, note that <code>stats</code> lets you calculate it directly without having to use <code>pmf</code> and then summing. The function is called <code>stats.distribution_name.cdf</code> where <code>distribution_name</code> could be <code>binom</code> or <code>poisson</code> or any other distribution name that <code>stats</code> recognizes. The first argument is $x$, followed by the parameters of the distribution in a specified order. In the case of the Poisson, there is just one parameter $\mu$.</p>
<p>For $X$ a Poisson $(4)$ random variable, the gold area above is $P(X \le 5)$ which is about 78.5%.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.78513038703040516</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Just to be sure, you can check that the answer is the same as what you would have got by summing the probabilities of the individual values:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">sum</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.78513038703040505</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    