---
redirect_from:
  - "/chapter-05/03-the-matching-problem"
interact_link: content/Chapter_05/03_The_Matching_Problem.ipynb
kernel_name: python3
kernel_path: content/Chapter_05
has_widgets: false
title: |-
  The Matching Problem
pagenum: 27
prev_page:
  url: /Chapter_05/02_Inclusion_Exclusion.html
next_page:
  url: /Chapter_05/04_Sampling_Without_Replacement.html
suffix: .ipynb
search: n frac k p sum text cdot big match cdots le envelope j letter matches chance align letters fixed position terms envelopes ai mn positions begin bigcup end matching problem any permutations random elements derangement mathop large places through permuted equally likely permutation ldots put once ways set event formula those e setting labeled also into points point range falls possible count good done remaining notice fix above second falling every inclusion exclusion least being added constant times therefore equal sim binom famous stated variously hats tea cups saucers indeed situation might want kinds items seems appeared somewhere randomly per

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">The Matching Problem</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Matching-Problem">The Matching Problem<a class="anchor-link" href="#The-Matching-Problem"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This famous problem has been stated variously in terms of hats and people, letters and envelopes, tea cups and saucers â€“ indeed, any situation in which you might want to match two kinds of items seems to have appeared somewhere as a setting for the matching problem.</p>
<p>In the letter-envelope setting there are $n$ letters labeled 1 through $n$ and also $n$ envelopes labeled 1 through $n$. The letters are permuted randomly into the envelopes, one letter per envelope (a mishap usually blamed on an unfortunate hypothetical secretary), so that all permutations are equally likely. The main questions are about the number of letters that are placed into their matching envelopes.</p>
<p>"Real life" settings aside, the problem is about the number of fixed points of a random permutation. A fixed point is an element whose position is unchanged by the shuffle.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Matches-at-Fixed-Locations">Matches at Fixed Locations<a class="anchor-link" href="#Matches-at-Fixed-Locations"> </a></h3><p>Consider a random permutation of $n$ elements which for simplicity we will call $\{1, 2, \ldots , n\}$. For any $i$ in the range 1 through $n$, what is the chance that Position $i$ is a fixed point? In other words, what is the chance that letter $i$ falls in envelope $i$?</p>
<p>We know that there are $n!$ possible permutations, all of which are equally likely. To find $P(\text{match at Position }i)$ all we have to do is count the number of permutations that put letter $i$ in envelope $i$. Here is a good way to count these:</p>
<ul>
<li>Put letter $i$ in envelope $i$.</li>
<li>Once that is done, the remaining $n-1$ letters can be permuted in $(n-1)!$ ways.</li>
</ul>
<p>So</p>
$$
P(\text{match at Position }i) = \frac{(n-1)!}{n!} 
= \frac{1}{n}
$$<p>Notice the absence of $i$ from the answer. No matter which position you fix, the chance of a match at that position is $1/n$. This formalizes the intuitive notion that each letter is equally likely to fall in any envelope, so the chance that it falls in the matching envelope is $1/n$.</p>
<p>Now fix any pair of positions $i \ne j$. To find $P(\text{matches at Positions } i \text{ and } j)$, extend the method we used above:</p>
<ul>
<li>Put letter $i$ in envelope $i$ and letter $j$ in envelope $j$.</li>
<li>Once that is done, the remaining $n-2$ letters can be permuted in $(n-2)!$ ways.</li>
</ul>
<p>So</p>
$$
P(\text{matches at Positions } i \text{ and } j) = 
\frac{(n-2)!}{n!} 
= \frac{1}{n} \cdot \frac{1}{n-1}
$$<p>The second term in the product is 
$P(\text{match at } j \mid \text{match at } i)$ and is just the chance of a match at a fixed spot in the reduced set of $n-1$ letters after letter $i$ and envelope $i$ have been removed.</p>
<p>You should check by induction that for $k = 1, 2, \ldots , n$,</p>
$$
P(\text{matches at a specified set of } k \text{ positions})
= \frac{1}{n} \cdot \frac{1}{n-1} \cdot \cdots \cdot \frac{1}{n-k+1}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="No-Matches">No Matches<a class="anchor-link" href="#No-Matches"> </a></h3><p>If letters falling in the right envelopes are good events, then the worst possible event is every letter falling in a wrong envelope. That is the event that there are no matches, and is called a <em>derangement</em>. Let's find the chance of a derangement.</p>
<p>The key is to notice that the complement is a union, and then use the inclusion-exclusion formula.</p>
$$
\begin{align*}P(\text{no match}) &amp;= 1 - P(\text{at least one match}) \\
&amp;= 1 - P\big{(}\bigcup_{i=1}^n \{\text{match at Position } i\} \big{)} \\
&amp;= 1 - P\big{(}\bigcup_{i=1}^n A_i \big{)}
\end{align*}
$$<p>where $A_i$ is the event "match at Position $i$".</p>
<p>By the inclusion-exclusion formula and our calculations above,</p>
$$
\begin{align*}
&amp; P\big{(}\bigcup_{i=1}^n A_i \big{)} \\
&amp;=
\sum_{i=1}^n P(A_i) - \mathop{\sum \sum}_{1 \le i &lt; j \le n} P(A_iA_j) + \mathop{\sum \sum \sum}_{1 \le i &lt; j &lt; k \le n} P(A_iA_jA_j) - \cdots + (-1)^{n+1} P(A_1A_2 \ldots A_n) \\
&amp;= \sum_{i=1}^n \frac{1}{n} - \mathop{\sum \sum}_{1 \le i &lt; j \le n} \frac{1}{n} \cdot \frac{1}{n-1} + 
\mathop{\sum \sum \sum}_{1 \le i &lt; j &lt; k \le n}
\frac{1}{n} \cdot \frac{1}{n-1} \cdot \frac{1}{n-2} -
\cdots + (-1)^{n+1} \frac{1}{n!}
\end{align*}
$$<p>If those sums look hair-raising, look again. None of the terms being added has an index ($i$, $j$, etc) in it! Each sum consists of adding a constant value multiple times, and is therefore equal to the constant times the number of terms in the sum.</p>
<p>The number of terms in the first sum is $n$. As we observed in an earlier section, the number of terms being added in the second sum is</p>
$$
\frac{n(n-1)}{2!}
$$<p>In the third sum the number of terms is</p>
$$
\frac{n(n-1)(n-2)}{3!}
$$<p>and so on. Therefore</p>
$$
\begin{align*}
&amp; P\big{(}\bigcup_{i=1}^n A_i \big{)} \\ \\
&amp;= n \cdot \frac{1}{n}
~-~ \frac{n(n-1)}{2!} \cdot \frac{1}{n} \cdot \frac{1}{n-1}
~+~ \frac{n(n-1)(n-2)}{3!} \cdot \frac{1}{n} \cdot \frac{1}{n-1} \cdot \frac{1}{n-2} ~-~
\cdots + (-1)^{n+1} \frac{1}{n!} \\ \\
&amp;= 1 - \frac{1}{2!} + \frac{1}{3!} - \cdots (-1)^{n+1}\frac{1}{n!}
\end{align*}
$$<p>Remember that</p>
$$
P\big{(}\bigcup_{i=1}^n A_i \big{)} = 
P(\text{at least one match})
$$<p>So the chance of a derangement is</p>
$$
\begin{align*}
P(\text{no match}) &amp;= 1 - \big{(}1 - \frac{1}{2!} + \frac{1}{3!} - \cdots (-1)^{n+1}\frac{1}{n!}\big{)} \\
&amp;= 1 - 1 + \frac{1}{2!} - \frac{1}{3!} + \cdots (-1)^n\frac{1}{n!} \\
&amp;\sim e^{-1}
\end{align*}
$$<p>when $n$ is large.</p>
<p>In the language of random variables, let $M_n$ be the number of fixed points (matches) in a random permutation of $n$ elements. Then for every $n \ge 1$ we have an exact formula for the chance that $M_n$ is 0:</p>
$$
P(M_n = 0) = 1 - 1 + \frac{1}{2!} - \frac{1}{3!} + \cdots (-1)^n\frac{1}{n!}
$$<p>For large $n$, we also have an approximation:</p>
$$
P(M_n = 0) \sim e^{-1} = 36.8\%
$$<p>roughly. When $n$ is large, about 36.8% of all permutations of $n$ elements move all of the elements away from their original positions.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="$k$-Matches">$k$ Matches<a class="anchor-link" href="#$k$-Matches"> </a></h3><p>For $0 \le k \le n$, you can find $P(M_n = k)$ by using the following observations.</p>
<ul>
<li>There are $\binom{n}{k}$ ways of fixing the $k$ places for the matches.</li>
<li>Once the places have been fixed, you have to get a match at those $k$ places; the chance of that is $1/(n(n-1) \cdots (n-k+1))$.</li>
<li>Given that there are matches at those $k$ places, there are $n-k$ letters left, with the corresponding $n-k$ envelopes, and there has to be a derangement of these. The conditional chance is equal to $P(M_{n-k} = 0)$.</li>
</ul>
<p>So for a fixed $k$ in the range $0 \le k \le n$,</p>
$$
\begin{align*}
&amp; P(M_n = k) \\
&amp;= \binom{n}{k} \cdot \frac{1}{n(n-1) \cdots (n-k+1)} \cdot 
\big{(} 1 - 1 + \frac{1}{2!} - \frac{1}{3!} + \cdots (-1)^{n-k}\frac{1}{(n-k)!} \big{)} \\
&amp;= \frac{1}{k!} \cdot \big{(} 1 - 1 + \frac{1}{2!} - \frac{1}{3!} + \cdots (-1)^{n-k}\frac{1}{(n-k)!} \big{)} \\
&amp;\approx \frac{1}{k!} e^{-1} ~~~~~~~~~ \text{for large } n
\end{align*}
$$<p>We will see later that these probabilities form a <em>Poisson</em> distribution on the infinite set of non-negative integers.</p>

</div>
</div>
</div>
</div>

 

<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script>


    </main>
    