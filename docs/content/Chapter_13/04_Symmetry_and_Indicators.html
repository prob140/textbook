

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>13.4. Symmetry and Indicators &#8212; Prob 140 Textbook</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/headers.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="13.5. Finite Population Correction" href="05_Finite_Population_Correction.html" />
    <link rel="prev" title="13.3. Sums of Independent Variables" href="03_Sums_of_Independent_Variables.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Prob 140 Textbook</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="http://prob140.org">
   Course Home
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../To_the_Student.html">
   To the  Student
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_01/00_Fundamentals.html">
   1. Fundamentals
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Outcome_Space_and_Events.html">
     1.1. Outcome Space and Events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Equally_Likely_Outcomes.html">
     1.2. Equally Likely Outcomes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Collisions_in_Hashing.html">
     1.3. Collisions in Hashing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Birthday_Problem.html">
     1.4. The Birthday Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/05_An_Exponential_Approximation.html">
     1.5. An Exponential Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/06_Exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_02/00_Calculating_Chances.html">
   2. Calculating Chances
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_Addition.html">
     2.1. Addition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Examples.html">
     2.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Multiplication.html">
     2.3. Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_More_Examples.html">
     2.4. More Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Updating_Probabilities.html">
     2.5. Updating Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_03/00_Random_Variables.html">
   3. Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Functions_on_an_Outcome_Space.html">
     3.1. Functions on an Outcome Space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Distributions.html">
     3.2. Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_Equality.html">
     3.3. Equality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_Exercises.html">
     3.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_04/00_Relations_Between_Variables.html">
   4. Relations Between Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Joint_Distributions.html">
     4.1. Joint Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Examples.html">
     4.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Marginal_Distributions.html">
     4.3. Marginal Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_Conditional_Distributions.html">
     4.4. Conditional Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Dependence_and_Independence.html">
     4.5. Dependence and Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/06_Exercises.html">
     4.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_05/00_Collections_of_Events.html">
   5. Collections of Events
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Bounding_the_Chance_of_a_Union.html">
     5.1. Bounding the Chance of a Union
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Inclusion_Exclusion.html">
     5.2. Inclusion-Exclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_The_Matching_Problem.html">
     5.3. The Matching Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Sampling_Without_Replacement.html">
     5.4. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Exercises.html">
     5.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_06/00_Random_Counts.html">
   6. Random Counts
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Binomial_Distribution.html">
     6.1. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Examples.html">
     6.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Multinomial_Distribution.html">
     6.3. Multinomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_The_Hypergeometric_Revisited.html">
     6.4. The Hypergeometric, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Odds_Ratios.html">
     6.5. Odds Ratios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/06_Law_of_Small_Numbers.html">
     6.6. The Law of Small Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/07_Exercises.html">
     6.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_07/00_Poissonization.html">
   7. Poissonization
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Poisson_Distribution.html">
     7.1. Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Poissonizing_the_Binomial.html">
     7.2. Poissonizing the Binomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_Poissonizing_the_Multinomial.html">
     7.3. Poissonizing the Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_08/00_Expectation.html">
   8. Expectation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Definition.html">
     8.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Applying_the_Definition.html">
     8.2. Applying the Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Expectations_of_Functions.html">
     8.3. Expectations of Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_Additivity.html">
     8.4. Additivity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Method_of_Indicators.html">
     8.5. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/06_Exercises.html">
     8.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_09/00_Conditioning_Revisited.html">
   9. Conditioning, Revisited
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Probability_by_Conditioning.html">
     9.1. Probability by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Expectation_by_Conditioning.html">
     9.2. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Expected_Waiting_Times.html">
     9.3. Expected Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_Exercises.html">
     9.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_10/00_Markov_Chains.html">
   10. Markov Chains
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Transitions.html">
     10.1. Transitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Deconstructing_Chains.html">
     10.2. Deconstructing Chains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_Long_Run_Behavior.html">
     10.3. Long Run Behavior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_Examples.html">
     10.4. Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_11/00_Markov_Chain_Monte_Carlo.html">
   11. Markov Chain Monte Carlo
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/01_Balance_and_Detailed_Balance.html">
     11.1. Balance and Detailed Balance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/02_Code_Breaking.html">
     11.2. Code Breaking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/03_Metropolis_Algorithm.html">
     11.3. Metropolis Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/04_Exercises.html">
     11.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_12/00_Standard_Deviation.html">
   12. Standard Deviation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/01_Definition.html">
     12.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/02_Prediction_and_Estimation.html">
     12.2. Prediction and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/03_Bounds.html">
     12.3. Tail Bounds
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/04_Heavy_Tails.html">
     12.4. Heavy Tails
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/05_Exercises.html">
     12.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="00_Variance_Via_Covariance.html">
   13. Variance Via Covariance
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_Covariance.html">
     13.1. Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_Properties_of_Covariance.html">
     13.2. Properties of Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_Sums_of_Independent_Variables.html">
     13.3. Sums of Independent Variables
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     13.4. Symmetry and Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_Finite_Population_Correction.html">
     13.5. Finite Population Correction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_Exercises.html">
     13.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_14/00_The_Central_Limit_Theorem.html">
   14. The Central Limit Theorem
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/01_Exact_Distribution.html">
     14.1. Exact Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/02_PGFs_in_NumPy.html">
     14.2. PGFs in NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/03_Central_Limit_Theorem.html">
     14.3. Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/04_The_Sample_Mean.html">
     14.4. The Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/05_Confidence_Intervals.html">
     14.5. Confidence Intervals
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_15/00_Continuous_Distributions.html">
   15. Continuous Distributions
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/01_Density_and_CDF.html">
     15.1. Density and CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/02_The_Meaning_of_Density.html">
     15.2. The Meaning of Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/03_Expectation.html">
     15.3. Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/04_Exponential_Distribution.html">
     15.4. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/05_Calculus_in_SymPy.html">
     15.5. Calculus in SymPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/06_Review_Problems_Set_3.html">
     15.6. Review Problems: Set 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_16/00_Transformations.html">
   16. Transformations
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/01_Linear_Transformations.html">
     16.1. Linear Transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/02_Monotone_Functions.html">
     16.2. Monotone Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/03_Two_to_One_Functions.html">
     16.3. Two-to-One Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_17/00_Joint_Densities.html">
   17. Joint Densities
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/01_Probabilities_and_Expectations.html">
     17.1. Probabilities and Expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/02_Independence.html">
     17.2. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/03_Marginal_and_Conditional_Densities.html">
     17.3. Marginal and Conditional Densities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/04_Beta_Densities_with_Integer_Parameters.html">
     17.4. Beta Densities with Integer Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_18/00_The_Normal_and_Gamma_Families.html">
   18. The Normal and Gamma Families
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/01_Standard_Normal_Basics.html">
     18.1. Standard Normal: The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/02_Sums_of_Independent_Normal_Variables.html">
     18.2. Sums of Independent Normal Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/03_The_Gamma_Family.html">
     18.3. The Gamma Family
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/04_Chi_Squared_Distributions.html">
     18.4. Chi-Squared Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/05_Review_Problems_Set_4.html">
     18.5. Review Problems: Set 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_19/00_Distributions_of_Sums.html">
   19. Distributions of Sums
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/01_Convolution_Formula.html">
     19.1. The Convolution Formula
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/02_Moment_Generating_Functions.html">
     19.2. Moment Generating Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/03_MGFs_Normal_and_the_CLT.html">
     19.3. MGFs, the Normal, and the CLT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/04_Chernoff_Bound.html">
     19.4. Chernoff Bound
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_20/00_Approaches_to_Estimation.html">
   20. Approaches to Estimation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/01_Maximum_Likelihood.html">
     20.1. Maximum Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/02_Prior_and_Posterior.html">
     20.2. Prior and Posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/03_Independence_Revisited.html">
     20.3. Independence, Revisited
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_21/00_The_Beta_and_the_Binomial.html">
   21. The Beta and the Binomial
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/01_Updating_and_Prediction.html">
     21.1. Updating and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/02_Beta_Binomial_Distribution.html">
     21.2. The Beta-Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/03_Long_Run_Proportion_of_Heads.html">
     21.3. Long Run Proportion of Heads
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_22/00_Prediction.html">
   22. Prediction
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/01_Conditional_Expectation_Projection.html">
     22.1. Conditional Expectation As a Projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/02_Variance_by_Conditioning.html">
     22.2. Variance by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/03_Examples.html">
     22.3. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/04_Least_Squares_Predictor.html">
     22.4. Least Squares Predictor
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_23/00_Multivariate_Normal_RVs.html">
   23. Jointly Normal Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/01_Random_Vectors.html">
     23.1. Random Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/02_Multivariate_Normal_Distribution.html">
     23.2. Multivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/03_Linear_Combinations.html">
     23.3. Linear Combinations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/04_Independence.html">
     23.4. Independence
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_24/00_Simple_Linear_Regression.html">
   24. Simple Linear Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/01_Bivariate_Normal_Distribution.html">
     24.1. Bivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/02_Linear_Least_Squares.html">
     24.2. Least Squares Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/03_Regression_and_Bivariate_Normal.html">
     24.3. Regression and the Bivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_24/04_Regression_Equation.html">
     24.4. The Regression Equation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_25/00_Multiple_Regression.html">
   25. Multiple Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/01_Bilinearity_in_Matrix_Notation.html">
     25.1. Bilinearity in Matrix Notation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/02_Best_Linear_Predictor.html">
     25.2. Best Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/03_Multivariate_Normal_Conditioning.html">
     25.3. Conditioning and the Multivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/04_Multiple_Regression.html">
     25.4. Multiple Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/05_Further_Review_Exercises.html">
     25.5. Further Review Exercises
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Chapter_13/04_Symmetry_and_Indicators.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://prob140.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/prob140/textbook&urlpath=tree/textbook/content/Chapter_13/04_Symmetry_and_Indicators.ipynb&branch=gh-pages"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#indicators">
   13.4.1. Indicators
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-of-the-hypergeometric">
   13.4.2. Variance of the Hypergeometric
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-of-a-simple-random-sample-sum">
   13.4.3. Variance of a Simple Random Sample Sum
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="symmetry-and-indicators">
<h1><span class="section-number">13.4. </span>Symmetry and Indicators<a class="headerlink" href="#symmetry-and-indicators" title="Permalink to this headline">¶</a></h1>
<p>When the random variables that are being added are not independent, finding the variance of the sum does involve finding covariances. As before, let <span class="math notranslate nohighlight">\(X_1, X_2, \ldots X_n\)</span> be random variables with sum</p>
<div class="math notranslate nohighlight">
\[
S_n = \sum_{i=1}^n X_i
\]</div>
<p>The variance of the sum is</p>
<div class="math notranslate nohighlight">
\[
Var(S_n) ~ = ~ \sum_{i=1}^n Var(X_i) + \mathop{\sum \sum}_{1 \le i \ne j \le n} Cov(X_i, X_j)
\]</div>
<p>Before we apply this formula, let’s start out by finding a simple covariance.</p>
<div class="section" id="indicators">
<h2><span class="section-number">13.4.1. </span>Indicators<a class="headerlink" href="#indicators" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> be two events. Let <span class="math notranslate nohighlight">\(I_A\)</span> be the indicator of <span class="math notranslate nohighlight">\(A\)</span> and let <span class="math notranslate nohighlight">\(I_B\)</span> be the indicator of  <span class="math notranslate nohighlight">\(B\)</span>. This is going to be one of the rare instances where we use an expected product to find a covariance. That’s because we know that products of indicators are themselves indicators.</p>
<div class="math notranslate nohighlight">
\[
Cov(I_A, I_B) = E(I_AI_B) - E(I_A)E(I_B) = P(AB) - P(A)P(B)
\]</div>
<p>You can see that the covariance is 0 if <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent, consistent with the more general result of the previous section. When <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are not independent, covariance helps us understand the nature of the dependence. For example, if <span class="math notranslate nohighlight">\(Cov(I_A, I_B)\)</span> is positive, then</p>
<div class="math notranslate nohighlight">
\[
P(AB) &gt; P(A)P(B) ~~~ \implies ~~~ P(A)P(B \mid A) &gt; P(A)P(B)
~~~ \implies ~~~ P(B \mid A) &gt; P(B)
\]</div>
<p>That is, given that <span class="math notranslate nohighlight">\(A\)</span> has occurred, the chance of <span class="math notranslate nohighlight">\(B\)</span> is higher than it is overall. This is called <em>positive association</em> or <em>positive dependence</em> of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>.</p>
</div>
<div class="section" id="variance-of-the-hypergeometric">
<h2><span class="section-number">13.4.2. </span>Variance of the Hypergeometric<a class="headerlink" href="#variance-of-the-hypergeometric" title="Permalink to this headline">¶</a></h2>
<p>Suppose you have a population of <span class="math notranslate nohighlight">\(N\)</span> elements of which <span class="math notranslate nohighlight">\(G\)</span> are good. Let <span class="math notranslate nohighlight">\(X\)</span> be the number of good elements in simple random sample of <span class="math notranslate nohighlight">\(n\)</span> elements drawn from the population. Remember that simple random samples are drawn without replacement.</p>
<p>We know that</p>
<div class="math notranslate nohighlight">
\[
X = \sum_{j=1}^n I_j
\]</div>
<p>where <span class="math notranslate nohighlight">\(I_j\)</span> is the indicator that draw <span class="math notranslate nohighlight">\(j\)</span> yields a good element.</p>
<p>By symmetry, we know that <span class="math notranslate nohighlight">\(E(I_j) = \frac{G}{N}\)</span> for each <span class="math notranslate nohighlight">\(j\)</span>. That is why</p>
<div class="math notranslate nohighlight">
\[
E(X) ~ = ~ n \frac{G}{N} ~ = ~ np ~~~~ \text{where } p = \frac{G}{N}
\]</div>
<p>That’s the same formula as for the binomial.</p>
<p>We also know that <span class="math notranslate nohighlight">\(Var(I_j) = \frac{G}{N} \cdot \frac{B}{N}\)</span> where <span class="math notranslate nohighlight">\(B = N-G\)</span> is the number of bad elements in the population.</p>
<p>Also by symmetry, <span class="math notranslate nohighlight">\(Cov(I_j, I_k)\)</span> is the same for each pair <span class="math notranslate nohighlight">\(j, k\)</span> where <span class="math notranslate nohighlight">\(j \ne k\)</span>. The example above tells us how to calculate this common value.</p>
<div class="math notranslate nohighlight">
\[
Cov(I_j, I_k) = \frac{G}{N} \cdot \frac{G-1}{N-1} - \frac{G}{N} \cdot \frac{G}{N}
\]</div>
<p>Therefore</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
Var(X) &amp;= \sum_{j=1}^n Var(I_j) + \mathop{\sum \sum}_{1 \le j \ne k \le n} Cov(I_j, I_k) \\ \\
&amp;= n \frac{G}{N} \cdot \frac{B}{N} ~ + ~ n(n-1) \Big{(} \frac{G}{N} \cdot \frac{G-1}{N-1} - \frac{G}{N} \cdot \frac{G}{N} \Big{)} \\ \\
&amp;= n \frac{G}{N} \cdot \frac{B}{N} ~ + ~ n(n-1) \frac{G}{N} \Big{(} \frac{G-1}{N-1} - \frac{G}{N} \Big{)} \\ \\
&amp;= n \frac{G}{N} \cdot \frac{B}{N} ~ - ~ n(n-1) \frac{G}{N} \cdot \frac{N-G}{N(N-1)} \\ \\
&amp;= n \frac{G}{N} \cdot \frac{B}{N} \cdot \Big{(} 1 - \frac{n-1}{N-1} \Big{)} \\ \\
&amp;= n \frac{G}{N} \cdot \frac{B}{N} \cdot \Big{(} \frac{N-n}{N-1} \Big{)} \\ \\
&amp;= npq \cdot \frac{N-n}{N-1}
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(p = \frac{G}{N}\)</span> and <span class="math notranslate nohighlight">\(q = 1-p\)</span>.</p>
<p>Notice that the formula is the same as the formula for the variance of the binomial, apart from the factor of <span class="math notranslate nohighlight">\(\frac{N-n}{N-1}\)</span>.</p>
<p>We can generalize this result to the case where the population isn’t binary.</p>
</div>
<div class="section" id="variance-of-a-simple-random-sample-sum">
<h2><span class="section-number">13.4.3. </span>Variance of a Simple Random Sample Sum<a class="headerlink" href="#variance-of-a-simple-random-sample-sum" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have a population of <span class="math notranslate nohighlight">\(N\)</span> numbers which need not be only zeros and ones. Suppose the population has mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>. Draw a simple random sample of size <span class="math notranslate nohighlight">\(n\)</span> from the population. For <span class="math notranslate nohighlight">\(j\)</span> in the range 1 through <span class="math notranslate nohighlight">\(n\)</span>, let <span class="math notranslate nohighlight">\(X_j\)</span> be the <span class="math notranslate nohighlight">\(j\)</span>th value drawn.</p>
<p>Let <span class="math notranslate nohighlight">\(S_n = X_1 + X_2 + \cdots + X_n\)</span>. Then <span class="math notranslate nohighlight">\(E(S_n) = n\mu\)</span>, and</p>
<div class="math notranslate nohighlight">
\[
Var(S_n) ~ = ~ \sum_{i=1}^n Var(X_i) + \mathop{\sum \sum}_{1 \le i \ne j \le n} Cov(X_i, X_j) ~ = ~ n\sigma^2 + n(n-1)Cov(X_1, X_2)
\]</div>
<p>by symmetry.</p>
<p>How can we find <span class="math notranslate nohighlight">\(Cov(X_1, X_2)\)</span>? It’s not a good idea to try and multiply the two variables, as they are dependent and their distributions might be unpleasant. The expected product will be hard to find.</p>
<p>What we can use is the observation that the equation we derived above for <span class="math notranslate nohighlight">\(Var(S_n)\)</span> is valid for any sample size. In particular, it is valid in the case when we take a census, that is, when we sample all the elements of the population. In that case <span class="math notranslate nohighlight">\(n = N\)</span> and the equation is</p>
<div class="math notranslate nohighlight">
\[
Var(S_N) = N\sigma^2 + N(N-1)Cov(X_1, X_2)
\]</div>
<p>Why is helpful? To answer this, think about the variability in <span class="math notranslate nohighlight">\(S_N\)</span>. We have sampled the entire population without replacement. Therefore <span class="math notranslate nohighlight">\(S_N\)</span> is just the total of the entire population. There is no sampling variability in <span class="math notranslate nohighlight">\(S_N\)</span>, because there is only one possible sample of size <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>That means <span class="math notranslate nohighlight">\(Var(S_N) = 0\)</span>. We can use this to solve for <span class="math notranslate nohighlight">\(Cov(X_1, X_2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[
0 = N\sigma^2 + N(N-1)Cov(X_1, X_2) ~~~~~ \implies ~~~~~
Cov(X_1, X_2) = -\frac{\sigma^2}{N-1}
\]</div>
<p>Now plug this into the formula for <span class="math notranslate nohighlight">\(Var(S_n)\)</span> for any smaller sample size <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="math notranslate nohighlight">
\[
Var(S_n) ~ = ~ n\sigma^2 - n(n-1)\frac{\sigma^2}{N-1} ~ = ~
n\sigma^2 \Big{(} 1 - \frac{n-1}{N-1} \Big{)} ~ = ~
n\sigma^2 \frac{N-n}{N-1}
\]</div>
<p>Recall that the variance of the sample sum is <span class="math notranslate nohighlight">\(n\sigma^2\)</span> when the sample is drawn with replacement. When the sample is drawn without replacement, the formula is the same apart from the factor of <span class="math notranslate nohighlight">\(\frac{N-n}{N-1}\)</span>.</p>
<p>That is exactly what we saw in the special case of the binary population. In the final section of this chapter we will investigate this relation between sampling with and without replacement.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/Chapter_13"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="03_Sums_of_Independent_Variables.html" title="previous page"><span class="section-number">13.3. </span>Sums of Independent Variables</a>
    <a class='right-next' id="next-link" href="05_Finite_Population_Correction.html" title="next page"><span class="section-number">13.5. </span>Finite Population Correction</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>