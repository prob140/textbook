

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>24.2. Bivariate Normal Distribution &#8212; Prob 140 Textbook</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/headers.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="24.3. Regression and the Bivariate Normal" href="03_Regression_and_Bivariate_Normal.html" />
    <link rel="prev" title="24.1. Least Squares Linear Predictor" href="01_Linear_Least_Squares.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Prob 140 Textbook</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="http://prob140.org">
   Course Home
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../To_the_Student.html">
   To the  Student
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_01/00_Fundamentals.html">
   1. Fundamentals
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/01_Outcome_Space_and_Events.html">
     1.1. Outcome Space and Events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/02_Equally_Likely_Outcomes.html">
     1.2. Equally Likely Outcomes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/03_Collisions_in_Hashing.html">
     1.3. Collisions in Hashing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/04_Birthday_Problem.html">
     1.4. The Birthday Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/05_An_Exponential_Approximation.html">
     1.5. An Exponential Approximation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_01/06_Exercises.html">
     1.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_02/00_Calculating_Chances.html">
   2. Calculating Chances
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/01_Addition.html">
     2.1. Addition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/02_Examples.html">
     2.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/03_Multiplication.html">
     2.3. Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/04_More_Examples.html">
     2.4. More Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/05_Updating_Probabilities.html">
     2.5. Updating Probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_02/06_Exercises.html">
     2.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_03/00_Random_Variables.html">
   3. Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/01_Functions_on_an_Outcome_Space.html">
     3.1. Functions on an Outcome Space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/02_Distributions.html">
     3.2. Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/03_Equality.html">
     3.3. Equality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_03/04_Exercises.html">
     3.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_04/00_Relations_Between_Variables.html">
   4. Relations Between Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/01_Joint_Distributions.html">
     4.1. Joint Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/02_Examples.html">
     4.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/03_Marginal_Distributions.html">
     4.3. Marginal Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/04_Conditional_Distributions.html">
     4.4. Conditional Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/05_Dependence_and_Independence.html">
     4.5. Dependence and Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_04/06_Exercises.html">
     4.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_05/00_Collections_of_Events.html">
   5. Collections of Events
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/01_Bounding_the_Chance_of_a_Union.html">
     5.1. Bounding the Chance of a Union
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/02_Inclusion_Exclusion.html">
     5.2. Inclusion-Exclusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/03_The_Matching_Problem.html">
     5.3. The Matching Problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/04_Sampling_Without_Replacement.html">
     5.4. Sampling Without Replacement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_05/05_Exercises.html">
     5.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_06/00_Random_Counts.html">
   6. Random Counts
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/01_Binomial_Distribution.html">
     6.1. The Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/02_Examples.html">
     6.2. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/03_Multinomial_Distribution.html">
     6.3. Multinomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/04_The_Hypergeometric_Revisited.html">
     6.4. The Hypergeometric, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/05_Odds_Ratios.html">
     6.5. Odds Ratios
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/06_Law_of_Small_Numbers.html">
     6.6. The Law of Small Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_06/07_Exercises.html">
     6.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_07/00_Poissonization.html">
   7. Poissonization
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/01_Poisson_Distribution.html">
     7.1. Poisson Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/02_Poissonizing_the_Binomial.html">
     7.2. Poissonizing the Binomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/03_Poissonizing_the_Multinomial.html">
     7.3. Poissonizing the Multinomial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_07/04_Exercises.html">
     7.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_08/00_Expectation.html">
   8. Expectation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/01_Definition.html">
     8.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/02_Applying_the_Definition.html">
     8.2. Applying the Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/03_Expectations_of_Functions.html">
     8.3. Expectations of Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/04_Additivity.html">
     8.4. Additivity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/05_Method_of_Indicators.html">
     8.5. Method of Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_08/06_Exercises.html">
     8.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_09/00_Conditioning_Revisited.html">
   9. Conditioning, Revisited
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/01_Probability_by_Conditioning.html">
     9.1. Probability by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/02_Expectation_by_Conditioning.html">
     9.2. Expectation by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/03_Expected_Waiting_Times.html">
     9.3. Expected Waiting Times
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_09/04_Exercises.html">
     9.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_10/00_Markov_Chains.html">
   10. Markov Chains
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/01_Transitions.html">
     10.1. Transitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/02_Deconstructing_Chains.html">
     10.2. Deconstructing Chains
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/03_Long_Run_Behavior.html">
     10.3. Long Run Behavior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_10/04_Examples.html">
     10.4. Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_11/00_Markov_Chain_Monte_Carlo.html">
   11. Markov Chain Monte Carlo
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/01_Balance_and_Detailed_Balance.html">
     11.1. Balance and Detailed Balance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/02_Code_Breaking.html">
     11.2. Code Breaking
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/03_Metropolis_Algorithm.html">
     11.3. Metropolis Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_11/04_Exercises.html">
     11.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_12/00_Standard_Deviation.html">
   12. Standard Deviation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/01_Definition.html">
     12.1. Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/02_Prediction_and_Estimation.html">
     12.2. Prediction and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/03_Bounds.html">
     12.3. Tail Bounds
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/04_Heavy_Tails.html">
     12.4. Heavy Tails
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_12/05_Exercises.html">
     12.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_13/00_Variance_Via_Covariance.html">
   13. Variance Via Covariance
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/01_Covariance.html">
     13.1. Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/02_Properties_of_Covariance.html">
     13.2. Properties of Covariance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/03_Sums_of_Independent_Variables.html">
     13.3. Sums of Independent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/04_Symmetry_and_Indicators.html">
     13.4. Symmetry and Indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/05_Finite_Population_Correction.html">
     13.5. Finite Population Correction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_13/06_Exercises.html">
     13.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_14/00_The_Central_Limit_Theorem.html">
   14. The Central Limit Theorem
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/01_Exact_Distribution_of_a_Sum.html">
     14.1. Exact Distribution of a Sum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/02_PGFs_in_NumPy.html">
     14.2. PGFs in NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/03_Central_Limit_Theorem.html">
     14.3. Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/04_SciPy_and_Normal_Curves.html">
     14.4. SciPy and Normal Curves
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/05_The_Sample_Mean.html">
     14.5. The Sample Mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/06_Confidence_Intervals.html">
     14.6. Confidence Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_14/07_Exercises.html">
     14.7. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_15/00_Continuous_Distributions.html">
   15. Continuous Distributions
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/01_Density_and_CDF.html">
     15.1. Density and CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/02_The_Meaning_of_Density.html">
     15.2. The Meaning of Density
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/03_Expectation.html">
     15.3. Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/04_Exponential_Distribution.html">
     15.4. Exponential Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/05_Calculus_in_SymPy.html">
     15.5. Calculus in SymPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_15/06_Exercises.html">
     15.6. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_16/00_Transformations.html">
   16. Transformations
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/01_Linear_Transformations.html">
     16.1. Linear Transformations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/02_Monotone_Functions.html">
     16.2. Monotone Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/03_Simulation_via_the_CDF.html">
     16.3. Simulation via the CDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/04_Two_to_One_Functions.html">
     16.4. Two-to-One Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_16/05_Exercises.html">
     16.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_17/00_Joint_Densities.html">
   17. Joint Densities
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/01_Probabilities_and_Expectations.html">
     17.1. Probabilities and Expectations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/02_Independence.html">
     17.2. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/03_Marginal_and_Conditional_Densities.html">
     17.3. Marginal and Conditional Densities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/04_Beta_Densities_with_Integer_Parameters.html">
     17.4. Beta Densities with Integer Parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_17/05_Exercises.html">
     17.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_18/00_The_Normal_and_Gamma_Families.html">
   18. The Normal and Gamma Families
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/01_Standard_Normal_Basics.html">
     18.1. Standard Normal: The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/02_Sums_of_Independent_Normal_Variables.html">
     18.2. Sums of Independent Normal Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/03_The_Gamma_Family.html">
     18.3. The Gamma Family
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/04_Chi_Squared_Distributions.html">
     18.4. Chi-Squared Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_18/05_Exercises.html">
     18.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_19/00_Distributions_of_Sums.html">
   19. Distributions of Sums
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/01_Convolution_Formula.html">
     19.1. The Convolution Formula
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/02_Moment_Generating_Functions.html">
     19.2. Moment Generating Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/03_MGFs_Normal_and_the_CLT.html">
     19.3. MGFs, the Normal, and the CLT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/04_Chernoff_Bound.html">
     19.4. Chernoff Bound
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_19/05_Exercises.html">
     19.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_20/00_Approaches_to_Estimation.html">
   20. Approaches to Estimation
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/01_Maximum_Likelihood.html">
     20.1. Maximum Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/02_Independence_Revisited.html">
     20.2. Independence, Revisited
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/03_Prior_and_Posterior.html">
     20.3. Prior and Posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_20/04_Exercises.html">
     20.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_21/00_The_Beta_and_the_Binomial.html">
   21. The Beta and the Binomial
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/01_Updating_and_Prediction.html">
     21.1. Updating and Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/02_Beta_Binomial_Distribution.html">
     21.2. The Beta-Binomial Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/03_Long_Run_Proportion_of_Heads.html">
     21.3. Long Run Proportion of Heads
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_21/04_Exercises.html">
     21.4. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_22/00_Prediction.html">
   22. Prediction
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/01_Conditional_Expectation_Projection.html">
     22.1. Conditional Expectation As a Projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/02_Least_Squares_Predictor.html">
     22.2. Least Squares Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/03_Variance_by_Conditioning.html">
     22.3. Variance by Conditioning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/04_Examples.html">
     22.4. Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_22/05_Exercises.html">
     22.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_23/00_Multivariate_Normal_RVs.html">
   23. Jointly Normal Random Variables
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/01_Random_Vectors.html">
     23.1. Random Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/02_Multivariate_Normal_Distribution.html">
     23.2. Multivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/03_Linear_Combinations.html">
     23.3. Linear Combinations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/04_Independence.html">
     23.4. Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_23/05_Exercises.html">
     23.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="00_Simple_Linear_Regression.html">
   24. Simple Linear Regression
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_Linear_Least_Squares.html">
     24.1. Least Squares Linear Predictor
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     24.2. Bivariate Normal Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_Regression_and_Bivariate_Normal.html">
     24.3. Regression and the Bivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_Regression_Equation.html">
     24.4. The Regression Equation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_Exercises.html">
     24.5. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Chapter_25/00_Multiple_Regression.html">
   25. Multiple Regression
  </a>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/01_Bilinearity_in_Matrix_Notation.html">
     25.1. Bilinearity in Matrix Notation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/02_Best_Linear_Predictor.html">
     25.2. Best Linear Predictor
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/03_Multivariate_Normal_Conditioning.html">
     25.3. Conditioning and the Multivariate Normal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Chapter_25/04_Multiple_Regression.html">
     25.4. Multiple Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Chapter_24/02_Bivariate_Normal_Distribution.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> On this page
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-correlation">
   24.2.1. Properties of Correlation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation-as-a-cosine">
   24.2.2. Correlation as a Cosine
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#constructing-the-standard-bivariate-normal">
   24.2.3. Constructing the Standard Bivariate Normal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representations-of-the-bivariate-normal">
   24.2.4. Representations of the Bivariate Normal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standard-bivariate-normal-matrix-approach">
   24.2.5. Standard Bivariate Normal: Matrix Approach
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlation-as-a-cosine-geometry-in-the-bivariate-normal-case">
   24.2.6. Correlation as a Cosine: Geometry in the Bivariate Normal Case
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#small-theta">
   24.2.7. Small
   <span class="math notranslate nohighlight">
    \(\theta\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#orthogonality-and-independence">
   24.2.8. Orthogonality and Independence
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="bivariate-normal-distribution">
<h1><span class="section-number">24.2. </span>Bivariate Normal Distribution<a class="headerlink" href="#bivariate-normal-distribution" title="Permalink to this headline">¶</a></h1>
<p>When the joint distribution of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is bivariate normal, the regression line of the previous section does even better than just being the best among all linear predictors of <span class="math notranslate nohighlight">\(Y\)</span> based on <span class="math notranslate nohighlight">\(X\)</span>. In this section we will construct a bivariate normal pair <span class="math notranslate nohighlight">\((X, Y)\)</span> from i.i.d. standard normal variables. In the next section, we will identify the main property of the regression line for bivariate normal <span class="math notranslate nohighlight">\((X, Y)\)</span>.</p>
<p>The multivariate normal distribution is defined in terms of a mean vector and a covariance matrix. As you know, normalizing the covariance makes it is easier to interpret. You have shown in exercises that for jointly distributed random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> the <em>correlation</em> between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
r_{X,Y} ~ = ~ \frac{Cov(X, Y)}{\sigma_X\sigma_Y} ~ = ~ 
E\Big{(}  \frac{X-\mu_X}{\sigma_X}  \cdot \frac{Y-\mu_Y}{\sigma_Y}  \Big{)}
~ = ~ E(X_{su}Y_{su})
\]</div>
<p>where <span class="math notranslate nohighlight">\(X_{su}\)</span> is <span class="math notranslate nohighlight">\(X\)</span> in standard units and <span class="math notranslate nohighlight">\(Y_{su}\)</span> is <span class="math notranslate nohighlight">\(Y\)</span> in standard units.</p>
<div class="section" id="properties-of-correlation">
<h2><span class="section-number">24.2.1. </span>Properties of Correlation<a class="headerlink" href="#properties-of-correlation" title="Permalink to this headline">¶</a></h2>
<p>You showed all of these in exercises.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r_{X,Y}\)</span> depends only on standard units and hence is a pure number with no units</p></li>
<li><p><span class="math notranslate nohighlight">\(r_{X,Y} = r_{Y,X}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(-1 \le r_{X,Y} \le 1\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(Y = aX + b\)</span> then <span class="math notranslate nohighlight">\(r_{X,Y}\)</span> is <span class="math notranslate nohighlight">\(1\)</span> or <span class="math notranslate nohighlight">\(-1\)</span> according to whether the sign of <span class="math notranslate nohighlight">\(a\)</span> is positive or negative.</p></li>
</ul>
<p>We say that <span class="math notranslate nohighlight">\(r_{X,Y}\)</span> measures the <em>linear association</em> between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
</div>
<div class="section" id="correlation-as-a-cosine">
<h2><span class="section-number">24.2.2. </span>Correlation as a Cosine<a class="headerlink" href="#correlation-as-a-cosine" title="Permalink to this headline">¶</a></h2>
<p>Rewrite the formula for correlation to see that</p>
<div class="math notranslate nohighlight">
\[
Cov(X, Y) ~ = ~ r_{X,Y}\sigma_X\sigma_Y
\]</div>
<p>So the variance of <span class="math notranslate nohighlight">\(X+Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\sigma_{X+Y}^2 ~ = ~ \sigma_X^2 + \sigma_Y^2 + 2r_{X,Y}\sigma_X\sigma_Y
\]</div>
<p>Notice the parallel with the formula for the length of the sum of two vectors, with correlation playing the role of the cosine of the angle between two vectors. If the angle is 90 degrees, the the cosine is 0. This corresponds to correlation being zero and hence the random variables being uncorrelated.</p>
<p>Later in this section, we will visualize this idea in the case where the joint distribution of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is bivariate normal.</p>
<div class="cell tag_remove-input tag_hide-output docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/d-ucYswhZ_Q"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="cell tag_remove-input tag_hide-output docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/GQ9nsyr3umI"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
</div>
<div class="section" id="constructing-the-standard-bivariate-normal">
<h2><span class="section-number">24.2.3. </span>Constructing the Standard Bivariate Normal<a class="headerlink" href="#constructing-the-standard-bivariate-normal" title="Permalink to this headline">¶</a></h2>
<p>The goal is to construct <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> that have the multivariate normal distribution with mean vector <span class="math notranslate nohighlight">\([0 ~ 0]^T\)</span> and covariance matrix
<span class="math notranslate nohighlight">\(\begin{bmatrix}
1 &amp; \rho \\
\rho &amp; 1
\end{bmatrix}\)</span>
for some <span class="math notranslate nohighlight">\(\rho\)</span> such that <span class="math notranslate nohighlight">\(0 &lt; \rho &lt; 1\)</span>. We will say that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> have the <em>standard bivariate normal distribution with correlation <span class="math notranslate nohighlight">\(\rho\)</span></em>.</p>
<p>Any bivariate normal vector is a linear transformation of an i.i.d. standard normal vector. Start with two i.i.d. standard normal random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>. We will construct the required bivariate normal random vector <span class="math notranslate nohighlight">\([X ~ Y]^T\)</span> as a linear transformation of the random vector <span class="math notranslate nohighlight">\([X ~ Z]^T\)</span>.</p>
<p>First note that since all three of <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span> must have mean <span class="math notranslate nohighlight">\(0\)</span>, the linear transformation has no shift term. We just need to identify numbers <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(c\)</span>, and <span class="math notranslate nohighlight">\(d\)</span> such that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
X \\
Y
\end{bmatrix}
~ = ~
\begin{bmatrix}
a &amp; b \\
c &amp; d
\end{bmatrix}
\begin{bmatrix}
X \\
Z
\end{bmatrix}
\end{split}\]</div>
<p>Taking <span class="math notranslate nohighlight">\(a=1\)</span> and <span class="math notranslate nohighlight">\(b=0\)</span> is a good start because it gives us the right first coordinate.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
1 &amp; 0 \\
c &amp; d
\end{bmatrix}
\begin{bmatrix}
X \\
Z
\end{bmatrix}
~=~
\begin{bmatrix}
X \\
cX+dZ
\end{bmatrix}
\end{split}\]</div>
<p>Since both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> must have variance <span class="math notranslate nohighlight">\(1\)</span>, the covariance of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is equal to the correlation. So, by the independence of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\rho ~ = ~ Cov(X, cX+dZ) ~ = ~ cVar(X) = c
\]</div>
<p>So now we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
1 &amp; 0 \\
\rho &amp; d
\end{bmatrix}
\begin{bmatrix}
X \\
Z
\end{bmatrix}
~=~
\begin{bmatrix}
X \\
\rho X+dZ
\end{bmatrix}
~ = ~ 
\begin{bmatrix}
X \\
Y
\end{bmatrix}
\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(Var(Y) = 1\)</span>, the final condition is <span class="math notranslate nohighlight">\(1 = Var(\rho X + dZ) = \rho^2Var(X) + d^2Var(Z) = rho^2 + d^2\)</span>. So <span class="math notranslate nohighlight">\(d = \sqrt{1 - \rho^2}\)</span> will work, and we have the following result.</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(X\)</span> be standard normal.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(Z\)</span> be standard normal, independent of <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(Y = \rho X + \sqrt{1-\rho^2}Z\)</span>.</p></li>
<li><p>Then <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> have the standard bivariate normal distribution with correlation <span class="math notranslate nohighlight">\(\rho\)</span>.</p></li>
</ul>
<p>It is also true that if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are standard bivariate normal with correlation <span class="math notranslate nohighlight">\(\rho\)</span>, then there is a standard normal <span class="math notranslate nohighlight">\(Z\)</span> independent of <span class="math notranslate nohighlight">\(X\)</span> such that <span class="math notranslate nohighlight">\(Y = \rho X + \sqrt{1-\rho^2}Z\)</span>. The proof is an exercise.</p>
<p>The graph below shows the empirical distribution of 1000 <span class="math notranslate nohighlight">\((X, Y)\)</span> points in the case <span class="math notranslate nohighlight">\(\rho = 0.6\)</span>. You can change the value of <span class="math notranslate nohighlight">\(rho\)</span> and see how the scatter diagram changes. It will remind you of numerous such simulations in Data 8.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting parameters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$X$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$Y$&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">))</span>

<span class="c1"># X, Z, and Y</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">rho</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rho</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">rho</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="n">z</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_8_0.png" src="../../_images/02_Bivariate_Normal_Distribution_8_0.png" />
</div>
</div>
</div>
<div class="section" id="representations-of-the-bivariate-normal">
<h2><span class="section-number">24.2.4. </span>Representations of the Bivariate Normal<a class="headerlink" href="#representations-of-the-bivariate-normal" title="Permalink to this headline">¶</a></h2>
<p>When we are working with just two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, matrix representations are usually unnecessary. We will use the following three representations interchangeably.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are bivariate normal with parameters <span class="math notranslate nohighlight">\((\mu_X, \mu_Y, \sigma_X^2, \sigma_Y^2, \rho)\)</span></p></li>
<li><p>The standardized variables <span class="math notranslate nohighlight">\(X_{su}\)</span> and <span class="math notranslate nohighlight">\(Y_{su}\)</span> are standard bivariate normal with correlation <span class="math notranslate nohighlight">\(\rho\)</span>. Then <span class="math notranslate nohighlight">\(Y_{su} = \rho X_{su} + \sqrt{1-\rho^2}Z\)</span> for some standard normal <span class="math notranslate nohighlight">\(Z\)</span> that is independent of <span class="math notranslate nohighlight">\(X_{su}\)</span>. This follows from Definition 2 of the multivariate normal.</p></li>
<li><p><span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> have the multivariate normal distribution with mean vector <span class="math notranslate nohighlight">\([\mu_X ~ \mu_Y]^T\)</span> and covariance matrix</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
\sigma_X^2 &amp; \rho\sigma_X\sigma_Y \\
\rho\sigma_X\sigma_Y &amp; \sigma_Y^2
\end{bmatrix}
\end{split}\]</div>
</div>
<div class="section" id="standard-bivariate-normal-matrix-approach">
<h2><span class="section-number">24.2.5. </span>Standard Bivariate Normal: Matrix Approach<a class="headerlink" href="#standard-bivariate-normal-matrix-approach" title="Permalink to this headline">¶</a></h2>
<p>In lab, you used a matrix approach to constructing standard bivariate normal <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> with correlation <span class="math notranslate nohighlight">\(\rho\)</span>. Here is a summary of the construction. The end result is the same as what we developed above.</p>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> be independent standard normal variables, that is, bivariate normal random variables with mean vector <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> and covariance matrix equal to the identity. Now fix a number <span class="math notranslate nohighlight">\(\rho\)</span> (that’s the Greek letter rho, the lower case r) so that <span class="math notranslate nohighlight">\(-1 &lt; \rho &lt; 1\)</span>, and let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{A} ~ = ~ 
\begin{bmatrix}
1 &amp; 0 \\
\rho &amp; \sqrt{1 - \rho^2}
\end{bmatrix}
\end{split}\]</div>
<p>Define a new random variable <span class="math notranslate nohighlight">\(Y = \rho X + \sqrt{1-\rho^2}Z\)</span>, and notice that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
X \\
Y
\end{bmatrix} 
~ = ~
\begin{bmatrix}
1 &amp; 0 \\
\rho &amp; \sqrt{1 - \rho^2}
\end{bmatrix}
\begin{bmatrix}
X \\
Z
\end{bmatrix}
~ = ~ 
\mathbf{A}
\begin{bmatrix}
X \\
Z
\end{bmatrix}
\end{split}\]</div>
<p>So <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> have the bivariate normal distribution with mean vector <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> and covariance matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{AIA}^T ~ = ~ 
\begin{bmatrix}
1 &amp; 0 \\
\rho &amp; \sqrt{1 - \rho^2}
\end{bmatrix}
\begin{bmatrix}
1 &amp; \rho \\
0 &amp; \sqrt{1 - \rho^2}
\end{bmatrix}
~ = ~ 
\begin{bmatrix}
1 &amp; \rho \\
\rho &amp; 1
\end{bmatrix}
\end{split}\]</div>
</div>
<div class="section" id="correlation-as-a-cosine-geometry-in-the-bivariate-normal-case">
<h2><span class="section-number">24.2.6. </span>Correlation as a Cosine: Geometry in the Bivariate Normal Case<a class="headerlink" href="#correlation-as-a-cosine-geometry-in-the-bivariate-normal-case" title="Permalink to this headline">¶</a></h2>
<p>We have defined</p>
<div class="math notranslate nohighlight">
\[
Y ~ = ~ \rho X + \sqrt{1 - \rho^2} Z
\]</div>
<p>where <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> are i.i.d. standard normal.</p>
<p>Let’s understand this construction geometrically. A good place to start is the joint density of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>, which has circular symmetry.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_12_0.png" src="../../_images/02_Bivariate_Normal_Distribution_12_0.png" />
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> axes are orthogonal. Let’s see what happens if we twist them.</p>
<p>Take any positive angle <span class="math notranslate nohighlight">\(\theta\)</span> degrees and draw a new axis at angle <span class="math notranslate nohighlight">\(\theta\)</span> to the original <span class="math notranslate nohighlight">\(X\)</span> axis. Every point <span class="math notranslate nohighlight">\((X, Z)\)</span> has a <em>projection</em> onto this axis.</p>
<p>The figure below shows the projection of the point <span class="math notranslate nohighlight">\((X, Z) = (1, 2)\)</span> onto the gold axis which is at an angle of <span class="math notranslate nohighlight">\(\theta\)</span> degress to the <span class="math notranslate nohighlight">\(X\)</span> axis. The blue segment is the value of <span class="math notranslate nohighlight">\(X\)</span>. You get that by dropping the perpendicular from <span class="math notranslate nohighlight">\((1, 2)\)</span> to the horizontal axis. That’s called <em>projecting</em> <span class="math notranslate nohighlight">\((1, 2)\)</span> onto the horizontal axis.</p>
<p>The red segment is the projection of <span class="math notranslate nohighlight">\((1, 2)\)</span> onto the gold axes, obtained by dropping the perpendicular from <span class="math notranslate nohighlight">\((1, 2)\)</span> to the gold axis.</p>
<p>Vary the values of <span class="math notranslate nohighlight">\(\theta\)</span> in the cell below to see how the projection changes as the gold axis rotates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">projection_1_2</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_14_0.png" src="../../_images/02_Bivariate_Normal_Distribution_14_0.png" />
</div>
</div>
<p>Let <span class="math notranslate nohighlight">\(Y\)</span> be the length of the red segment, and remember that <span class="math notranslate nohighlight">\(X\)</span> is the length of the blue segment. When <span class="math notranslate nohighlight">\(\theta\)</span> is very small, <span class="math notranslate nohighlight">\(Y\)</span> is almost equal to <span class="math notranslate nohighlight">\(X\)</span>. When <span class="math notranslate nohighlight">\(\theta\)</span> approaches 90 degrees, <span class="math notranslate nohighlight">\(Y\)</span> is almost equal to <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>A little trigonometry shows that <span class="math notranslate nohighlight">\(Y ~ = ~ X \cos(\theta) + Z\sin(\theta)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">projection_trig</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_16_0.png" src="../../_images/02_Bivariate_Normal_Distribution_16_0.png" />
</div>
</div>
<p>Thus</p>
<div class="math notranslate nohighlight">
\[
Y ~ = ~ X\cos(\theta) + Z\sin(\theta) ~ = ~ \rho X + \sqrt{1 - \rho^2}Z
\]</div>
<p>where <span class="math notranslate nohighlight">\(\rho = \cos(\theta)\)</span>.</p>
<p>The sequence of graphs below illustrates the transformation for <span class="math notranslate nohighlight">\(\theta = 30\)</span> degrees.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">projection_1_2</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_18_0.png" src="../../_images/02_Bivariate_Normal_Distribution_18_0.png" />
</div>
</div>
<p>The bivariate normal distribution is the joint distribution of the blue and red lengths <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> when the original point <span class="math notranslate nohighlight">\((X, Z)\)</span> has i.i.d. standard normal coordinates. This transforms the circular contours of the joint density surface of <span class="math notranslate nohighlight">\((X, Z)\)</span> into the elliptical contours of the joint density surface of <span class="math notranslate nohighlight">\((X, Y)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(0.8660254037844387, 0.8660254037844386)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">Plot_bivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">rho</span><span class="p">],</span> <span class="p">[</span><span class="n">rho</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Standard Bivariate Normal Distribution, Correlation = &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="mi">2</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_21_0.png" src="../../_images/02_Bivariate_Normal_Distribution_21_0.png" />
</div>
</div>
</div>
<div class="section" id="small-theta">
<h2><span class="section-number">24.2.7. </span>Small <span class="math notranslate nohighlight">\(\theta\)</span><a class="headerlink" href="#small-theta" title="Permalink to this headline">¶</a></h2>
<p>As we observed earlier, when <span class="math notranslate nohighlight">\(\theta\)</span> is very small there is hardly any change in the position of the axis. So <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are almost equal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">projection_1_2</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_23_0.png" src="../../_images/02_Bivariate_Normal_Distribution_23_0.png" />
</div>
</div>
<p>The bivariate normal density of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, therefore, is essentially confined to the <span class="math notranslate nohighlight">\(X = Y\)</span> line. The correlation <span class="math notranslate nohighlight">\(\cos(\theta)\)</span> is large because <span class="math notranslate nohighlight">\(\theta\)</span> is small; it is more than 0.999.</p>
<p>You can see the plotting function having trouble rendering this joint density surface.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">rho</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.9993908270190958
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Plot_bivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">rho</span><span class="p">],</span> <span class="p">[</span><span class="n">rho</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_26_0.png" src="../../_images/02_Bivariate_Normal_Distribution_26_0.png" />
</div>
</div>
</div>
<div class="section" id="orthogonality-and-independence">
<h2><span class="section-number">24.2.8. </span>Orthogonality and Independence<a class="headerlink" href="#orthogonality-and-independence" title="Permalink to this headline">¶</a></h2>
<p>When <span class="math notranslate nohighlight">\(\theta\)</span> is 90 degrees, the gold axis is orthogonal to the <span class="math notranslate nohighlight">\(X\)</span> axis and <span class="math notranslate nohighlight">\(Y\)</span> is equal to <span class="math notranslate nohighlight">\(Z\)</span> which is independent of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="mi">90</span>
<span class="n">projection_1_2</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02_Bivariate_Normal_Distribution_28_0.png" src="../../_images/02_Bivariate_Normal_Distribution_28_0.png" />
</div>
</div>
<p>When <span class="math notranslate nohighlight">\(\theta = 90\)</span> degrees, <span class="math notranslate nohighlight">\(\cos(\theta) = 0\)</span>. The joint density surface of <span class="math notranslate nohighlight">\((X, Y)\)</span> is the same as that of <span class="math notranslate nohighlight">\((X, Z)\)</span> and has circular symmetry.</p>
<p>If you think of <span class="math notranslate nohighlight">\(\rho X\)</span> as a “signal” and <span class="math notranslate nohighlight">\(\sqrt{1-\rho^2}Z\)</span> as “noise”, then <span class="math notranslate nohighlight">\(Y\)</span> can be thought of as an observation whose value is “signal plus noise”. In the rest of the chapter we will see if we can separate the signal from the noise.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/Chapter_24"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="01_Linear_Least_Squares.html" title="previous page"><span class="section-number">24.1. </span>Least Squares Linear Predictor</a>
    <a class='right-next' id="next-link" href="03_Regression_and_Bivariate_Normal.html" title="next page"><span class="section-number">24.3. </span>Regression and the Bivariate Normal</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ani Adhikari<br/>
        
            &copy; Copyright 2020.<br/>
          <div class="extra_footer">
            <p>
License: CC BY-NC-ND 4.0
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>